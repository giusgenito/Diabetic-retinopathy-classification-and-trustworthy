{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a336d13-ad71-4e90-8145-a8d6f91c6ad6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Preprocessing the Diabetic Retinopathy Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5c2a7c-8544-4d31-8693-cb888f962236",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b2b5b7-a7e5-4829-b318-fc6bcd16303c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9e876b-431e-4526-bdeb-96bedd997c3b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Import Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675f1b4c-b482-4a76-ad21-0351c24cd8ff",
   "metadata": {},
   "source": [
    "Some of this function are taken by this github repository: https://github.com/qqwweee/keras-yolo3/blob/master/yolo3/utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60d4354-4cbc-4368-912f-b99f867a6517",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compose(*funcs):\n",
    "    if funcs:\n",
    "        return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)\n",
    "    else:\n",
    "        raise ValueError('Composition of empty sequence not supported.')\n",
    "\n",
    "def letterbox_image(image_pil, target_size_wh, padding_color):\n",
    "    \"\"\"\n",
    "    Resizes an image to a target size while maintaining aspect ratio by adding padding.\n",
    "    The input image (image_pil) is expected to be a PIL Image.\n",
    "    The padding_color is an integer for grayscale images.\n",
    "    \"\"\"\n",
    "    iw, ih = image_pil.size\n",
    "    w_target, h_target = target_size_wh\n",
    "\n",
    "    if iw == 0 or ih == 0: # Handle empty input image\n",
    "        return Image.new('L', target_size_wh, padding_color)\n",
    "\n",
    "    scale = min(w_target/iw, h_target/ih)\n",
    "    nw = int(iw*scale)\n",
    "    nh = int(ih*scale)\n",
    "\n",
    "    # Ensure new dimensions are at least 1 pixel if scaled down significantly\n",
    "    nw = max(1, nw)\n",
    "    nh = max(1, nh)\n",
    "\n",
    "    resized_image = image_pil.resize((nw,nh), Image.BICUBIC)\n",
    "    \n",
    "    new_image = Image.new('L', target_size_wh, padding_color) # 'L' for grayscale\n",
    "    new_image.paste(resized_image, ((w_target-nw)//2, (h_target-nh)//2))\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df56baad-00da-4c39-9a4c-bd8f2159c0fd",
   "metadata": {},
   "source": [
    "## Defining the Preprocessing Pipeline using Function Composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9233c2-6796-437d-adeb-129b1c859bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_grayscale(img_bgr):\n",
    "    # If the image is already grayscale, do nothing\n",
    "    if len(img_bgr.shape) == 2: return img_bgr\n",
    "    if img_bgr.shape[2] == 1: return img_bgr.reshape(img_bgr.shape[0], img_bgr.shape[1])\n",
    "    \n",
    "    # Specific weights for BGR to Grayscale conversion\n",
    "    b, g, r = cv2.split(img_bgr)\n",
    "    gray_img = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "    return gray_img.astype(np.uint8)\n",
    "\n",
    "def apply_clahe(img_gray):\n",
    "    # Create and apply Contrast Limited Adaptive Histogram Equalization (CLAHE)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    return clahe.apply(img_gray)\n",
    "\n",
    "def apply_gaussian_blur(img_gray, kernel_size=(5,5)):\n",
    "    # Apply Gaussian Blur to the image\n",
    "    return cv2.GaussianBlur(img_gray, kernel_size, 0)\n",
    "\n",
    "def apply_median_filter(img_gray, kernel_size=5):\n",
    "    # Apply Median Filter to the image\n",
    "    return cv2.medianBlur(img_gray, kernel_size)\n",
    "\n",
    "def cv2_to_pil_grayscale(img_cv2):\n",
    "    # Convert a CV2 grayscale image to a PIL image\n",
    "    return Image.fromarray(img_cv2, mode='L')\n",
    "\n",
    "def pil_to_cv2_grayscale(img_pil):\n",
    "    # Convert a PIL grayscale image to a CV2 image (numpy array)\n",
    "    return np.array(img_pil)\n",
    "\n",
    "def segment_fundus_and_create_mask(image_cv2_gray, image_name_for_debug=\"\"):\n",
    "    \"\"\"\n",
    "    Segment the eye fundus and return a binary mask and the fundus' bounding box.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing (mask, bounding_box), where bounding_box is \n",
    "               (x, y, w, h) or None if no contour is found.\n",
    "    \"\"\"\n",
    "    # Tuning parameters for segmentation\n",
    "    blur_kernel_size_seg = (15, 15)  \n",
    "    threshold_value = 30  \n",
    "    morph_kernel_size_open = (15, 15)  # Kernel for MORPH_OPEN\n",
    "    morph_kernel_size_close = (35, 35) # Larger kernel for MORPH_CLOSE to merge regions\n",
    "    \n",
    "    blurred_for_seg = cv2.GaussianBlur(image_cv2_gray, blur_kernel_size_seg, 0)\n",
    "    \n",
    "    # Try cv2.THRESH_OTSU if a fixed threshold is not robust enough\n",
    "    # _, thresh_img = cv2.threshold(blurred_for_seg, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    _, thresh_img = cv2.threshold(blurred_for_seg, threshold_value, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    kernel_open = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, morph_kernel_size_open)\n",
    "    kernel_close = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, morph_kernel_size_close)\n",
    "    \n",
    "    # Apply morphological operations to clean up the binary mask\n",
    "    thresh_img = cv2.morphologyEx(thresh_img, cv2.MORPH_OPEN, kernel_open, iterations=1)\n",
    "    thresh_img = cv2.morphologyEx(thresh_img, cv2.MORPH_CLOSE, kernel_close, iterations=2)\n",
    "\n",
    "    contours, _ = cv2.findContours(thresh_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    mask = np.zeros_like(image_cv2_gray)\n",
    "    bounding_box = None\n",
    "\n",
    "    if contours:\n",
    "        contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "        # Consider filtering out contours that are too small relative to the image area\n",
    "        # min_area_ratio = 0.05 # Example: the contour must be at least 5% of the image\n",
    "        # if cv2.contourArea(contours[0]) > image_cv2_gray.shape[0] * image_cv2_gray.shape[1] * min_area_ratio:\n",
    "        \n",
    "        fundus_contour = contours[0]\n",
    "        hull = cv2.convexHull(fundus_contour)\n",
    "        cv2.drawContours(mask, [hull], -1, (255), thickness=cv2.FILLED)\n",
    "        bounding_box = cv2.boundingRect(hull) # Returns (x, y, w, h)\n",
    "        # else:\n",
    "        #     print(f\"Warning: Main contour is too small for {image_name_for_debug}. The resulting image might be black.\")\n",
    "    else:\n",
    "        print(f\"Warning: No fundus contour found for {image_name_for_debug}. The resulting image might be black.\")\n",
    "        \n",
    "    return mask, bounding_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559e6b58-bcf2-451f-b7c7-13d3dbb9eb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Global Parameters ---\n",
    "FINAL_IMAGE_SIZE = (512, 512)\n",
    "FUNDUS_TARGET_SCALE_FACTOR = 0.9 # The fundus will occupy 90% of the final image's largest dimension\n",
    "DEBUG_SAVE_INTERMEDIATE = False # Set to True to save debug images\n",
    "DEBUG_OUTPUT_DIR = '/home/jupyter-sdm/GENITO/LAVORO_COMPLETO/Dataset_resize/1_IDRiD_DEBUG/'\n",
    "if DEBUG_SAVE_INTERMEDIATE:\n",
    "    os.makedirs(DEBUG_OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e696ebde-47bd-4ff5-9479-263ea1aefe89",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 1 IDRiD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8b3ba4-eefb-4cca-b8c2-4289d47ed357",
   "metadata": {},
   "source": [
    "## IDRiD Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdba16a4-2a2e-4add-9a46-691a353e8079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- File and folder paths ---\n",
    "csv_path = '/home/jupyter-sdm/GENITO/DATASETS/1_IDRiD/a. IDRiD_Disease Grading_Training Labels.csv'\n",
    "image_dir = '/home/jupyter-sdm/GENITO/DATASETS/1_IDRiD/train'\n",
    "final_output_dir = '/home/jupyter-sdm/GENITO/LAVORO_COMPLETO/Dataset_resize/1_IDRiD/'\n",
    "file_extension = \".jpg\"\n",
    "column_class_name = 'Retinopathy grade'\n",
    "colum_image_name = 'Image name'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(csv_path)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: CSV file not found at {csv_path}\")\n",
    "    exit()\n",
    "\n",
    "# Create output directories for each class\n",
    "classes = df[column_class_name].unique()\n",
    "for cls in classes:\n",
    "    class_output_path = os.path.join(final_output_dir, str(cls))\n",
    "    os.makedirs(class_output_path, exist_ok=True)\n",
    "\n",
    "error_count = 0\n",
    "null_bbox_count = 0\n",
    "\n",
    "for _, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Processing Images\", ncols=100, ascii=True):\n",
    "    image_name_no_ext = row[colum_image_name]\n",
    "    image_name = image_name_no_ext + file_extension # Will be updated if a .jpeg is found\n",
    "    image_class = str(row[column_class_name])\n",
    "    src_path = os.path.join(image_dir, image_name_no_ext + file_extension) # Try .jpg first\n",
    "    output_class_path = os.path.join(final_output_dir, image_class)\n",
    "\n",
    "    # Handle cases where the image might have a .jpeg extension instead of .jpg\n",
    "    if not os.path.exists(src_path):\n",
    "        src_path_jpeg = os.path.join(image_dir, image_name_no_ext + \".jpeg\")\n",
    "        if os.path.exists(src_path_jpeg):\n",
    "            src_path = src_path_jpeg\n",
    "            image_name = image_name_no_ext + \".jpeg\" # Update the filename for output\n",
    "        else:\n",
    "            print(f\"Warning: {image_name_no_ext} (with .jpg/.jpeg extensions) not found in {image_dir}\")\n",
    "            error_count += 1\n",
    "            continue\n",
    "        \n",
    "    img_bgr = cv2.imread(src_path, cv2.IMREAD_COLOR)\n",
    "    \n",
    "    if img_bgr is None:\n",
    "        print(f\"Error reading {src_path}\")\n",
    "        error_count += 1\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # 1. Convert to Grayscale\n",
    "        img_cv2_gray = convert_to_grayscale(img_bgr)\n",
    "\n",
    "        # 2. Segment the fundus, create the mask, and get the bounding box\n",
    "        fundus_mask, fundus_bbox = segment_fundus_and_create_mask(img_cv2_gray.copy(), image_name)\n",
    "\n",
    "        if DEBUG_SAVE_INTERMEDIATE:\n",
    "            cv2.imwrite(os.path.join(DEBUG_OUTPUT_DIR, f\"{image_name_no_ext}_0_gray.png\"), img_cv2_gray)\n",
    "            cv2.imwrite(os.path.join(DEBUG_OUTPUT_DIR, f\"{image_name_no_ext}_1_mask.png\"), fundus_mask)\n",
    "\n",
    "        # 3. Apply CLAHE, Gaussian Blur, and Median Filter to the grayscale image\n",
    "        img_clahe = apply_clahe(img_cv2_gray)\n",
    "        img_gaussian_blurred = apply_gaussian_blur(img_clahe)\n",
    "        img_median_filtered = apply_median_filter(img_gaussian_blurred)\n",
    "        fully_processed_gray_data = img_median_filtered\n",
    "\n",
    "        if DEBUG_SAVE_INTERMEDIATE:\n",
    "             cv2.imwrite(os.path.join(DEBUG_OUTPUT_DIR, f\"{image_name_no_ext}_2_fully_processed_gray.png\"), fully_processed_gray_data)\n",
    "\n",
    "        # 4. Apply the mask to black out the background of the processed image\n",
    "        masked_processed_fundus_cv2 = cv2.bitwise_and(fully_processed_gray_data, fully_processed_gray_data, mask=fundus_mask)\n",
    "\n",
    "        if DEBUG_SAVE_INTERMEDIATE:\n",
    "            cv2.imwrite(os.path.join(DEBUG_OUTPUT_DIR, f\"{image_name_no_ext}_3_masked_fundus.png\"), masked_processed_fundus_cv2)\n",
    "\n",
    "        # --- Fundus Size Normalization ---\n",
    "        if fundus_bbox:\n",
    "            x, y, w_bbox, h_bbox = fundus_bbox\n",
    "            if w_bbox > 0 and h_bbox > 0:\n",
    "                # Crop the masked fundus using the bounding box\n",
    "                cropped_fundus_cv2 = masked_processed_fundus_cv2[y:y+h_bbox, x:x+w_bbox]\n",
    "\n",
    "                if DEBUG_SAVE_INTERMEDIATE:\n",
    "                    cv2.imwrite(os.path.join(DEBUG_OUTPUT_DIR, f\"{image_name_no_ext}_4_cropped_fundus.png\"), cropped_fundus_cv2)\n",
    "\n",
    "                # Calculate the new dimensions for the cropped fundus\n",
    "                target_max_dim_px = int(max(FINAL_IMAGE_SIZE) * FUNDUS_TARGET_SCALE_FACTOR)\n",
    "                \n",
    "                current_max_dim_bbox = max(w_bbox, h_bbox)\n",
    "                scale_ratio = target_max_dim_px / current_max_dim_bbox if current_max_dim_bbox > 0 else 1\n",
    "                \n",
    "                new_w = int(w_bbox * scale_ratio)\n",
    "                new_h = int(h_bbox * scale_ratio)\n",
    "                \n",
    "                # Ensure the new dimensions are at least 1x1\n",
    "                new_w = max(1, new_w)\n",
    "                new_h = max(1, new_h)\n",
    "\n",
    "                interpolation = cv2.INTER_AREA if scale_ratio < 1 else cv2.INTER_CUBIC\n",
    "                resized_cropped_fundus_cv2 = cv2.resize(cropped_cropped_fundus_cv2, (new_w, new_h), interpolation=interpolation)\n",
    "                \n",
    "                # Convert the normalized and resized fundus to a PIL image\n",
    "                image_to_letterbox_pil = cv2_to_pil_grayscale(resized_cropped_fundus_cv2)\n",
    "\n",
    "                if DEBUG_SAVE_INTERMEDIATE:\n",
    "                    image_to_letterbox_pil.save(os.path.join(DEBUG_OUTPUT_DIR, f\"{image_name_no_ext}_5_resized_cropped_fundus.png\"))\n",
    "            else:\n",
    "                # Invalid bounding box (e.g., width or height is 0)\n",
    "                print(f\"Warning: Invalid fundus bounding box for {image_name}. The image will be black.\")\n",
    "                image_to_letterbox_pil = Image.new('L', (1,1), 0) # Small placeholder image to be letterboxed\n",
    "                null_bbox_count +=1\n",
    "        else:\n",
    "            # No bounding box found (no contour)\n",
    "            print(f\"Warning: No fundus bounding box for {image_name}. The image will be black.\")\n",
    "            image_to_letterbox_pil = Image.new('L', (1,1), 0) # Placeholder image\n",
    "            null_bbox_count +=1\n",
    "            \n",
    "        # 5. Letterbox: place the image (now the normalized fundus) into a 512x512 canvas\n",
    "        #    The padding color is 0 (black) because the fundus background is already black.\n",
    "        letterboxed_img_pil = letterbox_image(image_to_letterbox_pil, FINAL_IMAGE_SIZE, padding_color=0) \n",
    "        \n",
    "        # 6. Convert back to a NumPy array (CV2) for saving\n",
    "        final_img_to_save = pil_to_cv2_grayscale(letterboxed_img_pil)\n",
    "        \n",
    "        # 7. Save the processed image\n",
    "        output_filename = os.path.splitext(image_name)[0] + '.png'\n",
    "        output_path = os.path.join(output_class_path, output_filename)\n",
    "        cv2.imwrite(output_path, final_img_to_save)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_name}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc() # Print the full traceback for easier debugging\n",
    "        error_count += 1\n",
    "        continue\n",
    "\n",
    "print(f\"Number of images that could not be read or had processing errors: {error_count}\")\n",
    "print(f\"Number of images with null or invalid fundus bounding box: {null_bbox_count}\")\n",
    "print(\"Splitting and preprocessing complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c1eed8-468b-44c9-a5ed-a16aebb98ca0",
   "metadata": {},
   "source": [
    "## IDRiD Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8072b0-5dc1-4e07-bab4-583a2bd17efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- File and folder paths ---\n",
    "csv_path = '/home/jupyter-sdm/GENITO/DATASETS/1_IDRiD/b. IDRiD_Disease Grading_Testing Labels.csv'\n",
    "image_dir = '/home/jupyter-sdm/GENITO/DATASETS/1_IDRiD/test'\n",
    "final_output_dir = '/home/jupyter-sdm/GENITO/LAVORO_COMPLETO/Dataset_resize/1_IDRiD/'\n",
    "\n",
    "file_extension = \".jpg\"\n",
    "column_class_name = 'Retinopathy grade'\n",
    "colum_image_name = 'Image name'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(csv_path)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: CSV file not found at {csv_path}\")\n",
    "    exit()\n",
    "\n",
    "# Create output directories for each class\n",
    "classes = df[column_class_name].unique()\n",
    "for cls in classes:\n",
    "    class_output_path = os.path.join(final_output_dir, str(cls))\n",
    "    os.makedirs(class_output_path, exist_ok=True)\n",
    "\n",
    "error_count = 0\n",
    "null_bbox_count = 0\n",
    "\n",
    "for _, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Processing Images\", ncols=100, ascii=True):\n",
    "    image_name_no_ext = row[colum_image_name]\n",
    "    image_name = image_name_no_ext + file_extension # Will be updated if a .jpeg is found\n",
    "    image_class = str(row[column_class_name])\n",
    "    src_path = os.path.join(image_dir, image_name_no_ext + file_extension) # Try .jpg first\n",
    "    output_class_path = os.path.join(final_output_dir, image_class)\n",
    "\n",
    "    # Handle cases where the image might have a .jpeg extension instead of .jpg\n",
    "    if not os.path.exists(src_path):\n",
    "        src_path_jpeg = os.path.join(image_dir, image_name_no_ext + \".jpeg\")\n",
    "        if os.path.exists(src_path_jpeg):\n",
    "            src_path = src_path_jpeg\n",
    "            image_name = image_name_no_ext + \".jpeg\" # Update the filename for output\n",
    "        else:\n",
    "            print(f\"Warning: {image_name_no_ext} (with .jpg/.jpeg extensions) not found in {image_dir}\")\n",
    "            error_count += 1\n",
    "            continue\n",
    "        \n",
    "    img_bgr = cv2.imread(src_path, cv2.IMREAD_COLOR)\n",
    "    \n",
    "    if img_bgr is None:\n",
    "        print(f\"Error reading {src_path}\")\n",
    "        error_count += 1\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # 1. Convert to Grayscale\n",
    "        img_cv2_gray = convert_to_grayscale(img_bgr)\n",
    "\n",
    "        # 2. Segment the fundus, create the mask, and get the bounding box\n",
    "        fundus_mask, fundus_bbox = segment_fundus_and_create_mask(img_cv2_gray.copy(), image_name)\n",
    "\n",
    "        if DEBUG_SAVE_INTERMEDIATE:\n",
    "            cv2.imwrite(os.path.join(DEBUG_OUTPUT_DIR, f\"{image_name_no_ext}_0_gray.png\"), img_cv2_gray)\n",
    "            cv2.imwrite(os.path.join(DEBUG_OUTPUT_DIR, f\"{image_name_no_ext}_1_mask.png\"), fundus_mask)\n",
    "\n",
    "        # 3. Apply CLAHE, Gaussian Blur, and Median Filter to the grayscale image\n",
    "        img_clahe = apply_clahe(img_cv2_gray)\n",
    "        img_gaussian_blurred = apply_gaussian_blur(img_clahe)\n",
    "        img_median_filtered = apply_median_filter(img_gaussian_blurred)\n",
    "        fully_processed_gray_data = img_median_filtered\n",
    "\n",
    "        if DEBUG_SAVE_INTERMEDIATE:\n",
    "             cv2.imwrite(os.path.join(DEBUG_OUTPUT_DIR, f\"{image_name_no_ext}_2_fully_processed_gray.png\"), fully_processed_gray_data)\n",
    "\n",
    "        # 4. Apply the mask to black out the background of the processed image\n",
    "        masked_processed_fundus_cv2 = cv2.bitwise_and(fully_processed_gray_data, fully_processed_gray_data, mask=fundus_mask)\n",
    "\n",
    "        if DEBUG_SAVE_INTERMEDIATE:\n",
    "            cv2.imwrite(os.path.join(DEBUG_OUTPUT_DIR, f\"{image_name_no_ext}_3_masked_fundus.png\"), masked_processed_fundus_cv2)\n",
    "\n",
    "        # --- Fundus Size Normalization ---\n",
    "        if fundus_bbox:\n",
    "            x, y, w_bbox, h_bbox = fundus_bbox\n",
    "            if w_bbox > 0 and h_bbox > 0:\n",
    "                # Crop the masked fundus using the bounding box\n",
    "                cropped_fundus_cv2 = masked_processed_fundus_cv2[y:y+h_bbox, x:x+w_bbox]\n",
    "\n",
    "                if DEBUG_SAVE_INTERMEDIATE:\n",
    "                    cv2.imwrite(os.path.join(DEBUG_OUTPUT_DIR, f\"{image_name_no_ext}_4_cropped_fundus.png\"), cropped_fundus_cv2)\n",
    "\n",
    "                # Calculate the new dimensions for the cropped fundus\n",
    "                target_max_dim_px = int(max(FINAL_IMAGE_SIZE) * FUNDUS_TARGET_SCALE_FACTOR)\n",
    "                \n",
    "                current_max_dim_bbox = max(w_bbox, h_bbox)\n",
    "                scale_ratio = target_max_dim_px / current_max_dim_bbox if current_max_dim_bbox > 0 else 1\n",
    "                \n",
    "                new_w = int(w_bbox * scale_ratio)\n",
    "                new_h = int(h_bbox * scale_ratio)\n",
    "                \n",
    "                # Ensure the new dimensions are at least 1x1\n",
    "                new_w = max(1, new_w)\n",
    "                new_h = max(1, new_h)\n",
    "\n",
    "                interpolation = cv2.INTER_AREA if scale_ratio < 1 else cv2.INTER_CUBIC\n",
    "                resized_cropped_fundus_cv2 = cv2.resize(cropped_fundus_cv2, (new_w, new_h), interpolation=interpolation)\n",
    "                \n",
    "                # Convert the normalized and resized fundus to a PIL image\n",
    "                image_to_letterbox_pil = cv2_to_pil_grayscale(resized_cropped_fundus_cv2)\n",
    "\n",
    "                if DEBUG_SAVE_INTERMEDIATE:\n",
    "                    image_to_letterbox_pil.save(os.path.join(DEBUG_OUTPUT_DIR, f\"{image_name_no_ext}_5_resized_cropped_fundus.png\"))\n",
    "            else:\n",
    "                # Invalid bounding box (e.g., width or height is 0)\n",
    "                print(f\"Warning: Invalid fundus bounding box for {image_name}. The image will be black.\")\n",
    "                image_to_letterbox_pil = Image.new('L', (1,1), 0) # Small placeholder image to be letterboxed\n",
    "                null_bbox_count +=1\n",
    "        else:\n",
    "            # No bounding box found (no contour)\n",
    "            print(f\"Warning: No fundus bounding box for {image_name}. The image will be black.\")\n",
    "            image_to_letterbox_pil = Image.new('L', (1,1), 0) # Placeholder image\n",
    "            null_bbox_count +=1\n",
    "            \n",
    "        # 5. Letterbox: place the image (now the normalized fundus) into a 512x512 canvas\n",
    "        #    The padding color is 0 (black) because the fundus background is already black.\n",
    "        letterboxed_img_pil = letterbox_image(image_to_letterbox_pil, FINAL_IMAGE_SIZE, padding_color=0) \n",
    "        \n",
    "        # 6. Convert back to a NumPy array (CV2) for saving\n",
    "        final_img_to_save = pil_to_cv2_grayscale(letterboxed_img_pil)\n",
    "        \n",
    "        # 7. Save the processed image\n",
    "        output_filename = os.path.splitext(image_name)[0] + '.png'\n",
    "        output_path = os.path.join(output_class_path, output_filename)\n",
    "        cv2.imwrite(output_path, final_img_to_save)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_name}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc() # Print the full traceback for easier debugging\n",
    "        error_count += 1\n",
    "        continue\n",
    "\n",
    "print(f\"Number of images that could not be read or had processing errors: {error_count}\")\n",
    "print(f\"Number of images with null or invalid fundus bounding box: {null_bbox_count}\")\n",
    "print(\"Splitting and preprocessing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2632f5-beb0-44d5-a1c1-b9d2b4fe70b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## IDRiD Check\n",
    "train_images_idrid_base = \"/home/jupyter-sdm/GENITO/LAVORO_COMPLETO/Dataset_resize/1_IDRiD\"\n",
    "num_train_images_idrid = sum(len(os.listdir(os.path.join(train_images_idrid_base, str(i)))) for i in range(5))\n",
    "\n",
    "print(f\"Total number of images in the IDRiD train set: {num_train_images_idrid}\")\n",
    "\n",
    "for cls in range(5):\n",
    "    num_images = len(os.listdir(os.path.join(train_images_idrid_base, str(cls))))\n",
    "    print(f\"Class {cls}: {num_images} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605171bc-78ba-4cb1-a0d0-2734338144e9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 2 APTOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7fee4b-129e-4ef2-8e1d-dd39462d111d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- File and folder paths ---\n",
    "csv_path = '/home/jupyter-sdm/GENITO/DATASETS/2_APTOS/train.csv' \n",
    "image_dir = '/home/jupyter-sdm/GENITO/DATASETS/2_APTOS/train'\n",
    "final_output_dir = '/home/jupyter-sdm/GENITO/LAVORO_COMPLETO/Dataset_resize/2_APTOS/'\n",
    "\n",
    "file_extension = \".png\"\n",
    "column_class_name = 'diagnosis'\n",
    "colum_image_name = 'id_code'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(csv_path)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: CSV file not found at {csv_path}\")\n",
    "    exit()\n",
    "\n",
    "# Create output directories for each class\n",
    "classes = df[column_class_name].unique()\n",
    "for cls in classes:\n",
    "    class_output_path = os.path.join(final_output_dir, str(cls))\n",
    "    os.makedirs(class_output_path, exist_ok=True)\n",
    "\n",
    "error_count = 0\n",
    "null_bbox_count = 0\n",
    "\n",
    "for _, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Processing Images\", ncols=100, ascii=True):\n",
    "    image_name_no_ext = row[colum_image_name]\n",
    "    image_name = image_name_no_ext + file_extension # Will be updated if a .jpeg is found\n",
    "    image_class = str(row[column_class_name])\n",
    "    src_path = os.path.join(image_dir, image_name_no_ext + file_extension) # Try .png first\n",
    "    output_class_path = os.path.join(final_output_dir, image_class)\n",
    "\n",
    "    # Handle cases where the image might have a different extension\n",
    "    if not os.path.exists(src_path):\n",
    "        src_path_jpeg = os.path.join(image_dir, image_name_no_ext + \".jpeg\")\n",
    "        if os.path.exists(src_path_jpeg):\n",
    "            src_path = src_path_jpeg\n",
    "            image_name = image_name_no_ext + \".jpeg\" # Update the filename for output\n",
    "        else:\n",
    "            print(f\"Warning: {image_name_no_ext} (with .png/.jpeg extensions) not found in {image_dir}\")\n",
    "            error_count += 1\n",
    "            continue\n",
    "        \n",
    "    img_bgr = cv2.imread(src_path, cv2.IMREAD_COLOR)\n",
    "    \n",
    "    if img_bgr is None:\n",
    "        print(f\"Error reading {src_path}\")\n",
    "        error_count += 1\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # 1. Convert to Grayscale\n",
    "        img_cv2_gray = convert_to_grayscale(img_bgr)\n",
    "\n",
    "        # 2. Segment the fundus, create the mask, and get the bounding box\n",
    "        fundus_mask, fundus_bbox = segment_fundus_and_create_mask(img_cv2_gray.copy(), image_name)\n",
    "\n",
    "        if DEBUG_SAVE_INTERMEDIATE:\n",
    "            cv2.imwrite(os.path.join(DEBUG_OUTPUT_DIR, f\"{image_name_no_ext}_0_gray.png\"), img_cv2_gray)\n",
    "            cv2.imwrite(os.path.join(DEBUG_OUTPUT_DIR, f\"{image_name_no_ext}_1_mask.png\"), fundus_mask)\n",
    "\n",
    "        # 3. Apply CLAHE, Gaussian Blur, and Median Filter to the grayscale image\n",
    "        img_clahe = apply_clahe(img_cv2_gray)\n",
    "        img_gaussian_blurred = apply_gaussian_blur(img_clahe)\n",
    "        img_median_filtered = apply_median_filter(img_gaussian_blurred)\n",
    "        fully_processed_gray_data = img_median_filtered\n",
    "\n",
    "        if DEBUG_SAVE_INTERMEDIATE:\n",
    "             cv2.imwrite(os.path.join(DEBUG_OUTPUT_DIR, f\"{image_name_no_ext}_2_fully_processed_gray.png\"), fully_processed_gray_data)\n",
    "\n",
    "        # 4. Apply the mask to black out the background of the processed image\n",
    "        masked_processed_fundus_cv2 = cv2.bitwise_and(fully_processed_gray_data, fully_processed_gray_data, mask=fundus_mask)\n",
    "\n",
    "        if DEBUG_SAVE_INTERMEDIATE:\n",
    "            cv2.imwrite(os.path.join(DEBUG_OUTPUT_DIR, f\"{image_name_no_ext}_3_masked_fundus.png\"), masked_processed_fundus_cv2)\n",
    "\n",
    "        # --- Fundus Size Normalization ---\n",
    "        if fundus_bbox:\n",
    "            x, y, w_bbox, h_bbox = fundus_bbox\n",
    "            if w_bbox > 0 and h_bbox > 0:\n",
    "                # Crop the masked fundus using the bounding box\n",
    "                cropped_fundus_cv2 = masked_processed_fundus_cv2[y:y+h_bbox, x:x+w_bbox]\n",
    "\n",
    "                if DEBUG_SAVE_INTERMEDIATE:\n",
    "                    cv2.imwrite(os.path.join(DEBUG_OUTPUT_DIR, f\"{image_name_no_ext}_4_cropped_fundus.png\"), cropped_fundus_cv2)\n",
    "\n",
    "                # Calculate the new dimensions for the cropped fundus\n",
    "                target_max_dim_px = int(max(FINAL_IMAGE_SIZE) * FUNDUS_TARGET_SCALE_FACTOR)\n",
    "                \n",
    "                current_max_dim_bbox = max(w_bbox, h_bbox)\n",
    "                scale_ratio = target_max_dim_px / current_max_dim_bbox if current_max_dim_bbox > 0 else 1\n",
    "                \n",
    "                new_w = int(w_bbox * scale_ratio)\n",
    "                new_h = int(h_bbox * scale_ratio)\n",
    "                \n",
    "                # Ensure the new dimensions are at least 1x1\n",
    "                new_w = max(1, new_w)\n",
    "                new_h = max(1, new_h)\n",
    "\n",
    "                interpolation = cv2.INTER_AREA if scale_ratio < 1 else cv2.INTER_CUBIC\n",
    "                resized_cropped_fundus_cv2 = cv2.resize(cropped_fundus_cv2, (new_w, new_h), interpolation=interpolation)\n",
    "                \n",
    "                # Convert the normalized and resized fundus to a PIL image\n",
    "                image_to_letterbox_pil = cv2_to_pil_grayscale(resized_cropped_fundus_cv2)\n",
    "\n",
    "                if DEBUG_SAVE_INTERMEDIATE:\n",
    "                    image_to_letterbox_pil.save(os.path.join(DEBUG_OUTPUT_DIR, f\"{image_name_no_ext}_5_resized_cropped_fundus.png\"))\n",
    "            else:\n",
    "                # Invalid bounding box (e.g., width or height is 0)\n",
    "                print(f\"Warning: Invalid fundus bounding box for {image_name}. The image will be black.\")\n",
    "                image_to_letterbox_pil = Image.new('L', (1,1), 0) # Small placeholder image to be letterboxed\n",
    "                null_bbox_count +=1\n",
    "        else:\n",
    "            # No bounding box found (no contour)\n",
    "            print(f\"Warning: No fundus bounding box for {image_name}. The image will be black.\")\n",
    "            image_to_letterbox_pil = Image.new('L', (1,1), 0) # Placeholder image\n",
    "            null_bbox_count +=1\n",
    "            \n",
    "        # 5. Letterbox: place the image (now the normalized fundus) into a 512x512 canvas\n",
    "        #    The padding color is 0 (black) because the fundus background is already black.\n",
    "        letterboxed_img_pil = letterbox_image(image_to_letterbox_pil, FINAL_IMAGE_SIZE, padding_color=0) \n",
    "        \n",
    "        # 6. Convert back to a NumPy array (CV2) for saving\n",
    "        final_img_to_save = pil_to_cv2_grayscale(letterboxed_img_pil)\n",
    "        \n",
    "        # 7. Save the processed image\n",
    "        output_filename = os.path.splitext(image_name)[0] + '.png'\n",
    "        output_path = os.path.join(output_class_path, output_filename)\n",
    "        cv2.imwrite(output_path, final_img_to_save)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_name}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc() # Print the full traceback for easier debugging\n",
    "        error_count += 1\n",
    "        continue\n",
    "\n",
    "print(f\"Number of images that could not be read or had processing errors: {error_count}\")\n",
    "print(f\"Number of images with null or invalid fundus bounding box: {null_bbox_count}\")\n",
    "print(\"Splitting and preprocessing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f02dd8a-9847-4260-9688-355aed792856",
   "metadata": {},
   "outputs": [],
   "source": [
    "## APTOS Check\n",
    "train_images_aptos_base = \"/home/jupyter-sdm/GENITO/LAVORO_COMPLETO/Dataset_resize/2_APTOS\"\n",
    "num_train_images_aptos = sum(len(os.listdir(os.path.join(train_images_aptos_base, str(i)))) for i in range(5))\n",
    "\n",
    "print(f\"Total number of images in the APTOS train set: {num_train_images_aptos}\")\n",
    "\n",
    "for cls in range(5):\n",
    "    num_images = len(os.listdir(os.path.join(train_images_aptos_base, str(cls))))\n",
    "    print(f\"Class {cls}: {num_images} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ea9dc0-7a87-4345-bdfc-2b2a4e42a7c5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 3 DeepDRiD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f41398-1106-4343-8da3-4662c02566fd",
   "metadata": {},
   "source": [
    "## DeepDRiD Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a79ff6a-b97c-4862-92c7-752134e88918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- File and folder paths ---\n",
    "csv_path = '/home/jupyter-sdm/GENITO/DATASETS/3_DeepDRiD/regular-fundus-training.csv'\n",
    "image_dir = '/home/jupyter-sdm/GENITO/DATASETS/3_DeepDRiD/train'\n",
    "final_output_dir = \"/home/jupyter-sdm/GENITO/LAVORO_COMPLETO/Dataset_resize/3_DeepDRiD\"\n",
    "\n",
    "file_extension = \".jpg\"\n",
    "column_class_name = 'patient_DR_Level'\n",
    "colum_image_name = 'image_id'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(csv_path)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: CSV file not found at {csv_path}\")\n",
    "    exit()\n",
    "\n",
    "# Create output directories for each class\n",
    "classes = df[column_class_name].unique()\n",
    "for cls in classes:\n",
    "    class_output_path = os.path.join(final_output_dir, str(cls))\n",
    "    os.makedirs(class_output_path, exist_ok=True)\n",
    "\n",
    "error_count = 0\n",
    "null_bbox_count = 0\n",
    "\n",
    "for _, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Processing Images\", ncols=100, ascii=True):\n",
    "    image_name_no_ext = row[colum_image_name]\n",
    "    image_name = image_name_no_ext + file_extension # Will be updated if a .jpeg is found\n",
    "    image_class = str(row[column_class_name])\n",
    "    src_path = os.path.join(image_dir, image_name_no_ext + file_extension) # Try .jpg first\n",
    "    output_class_path = os.path.join(final_output_dir, image_class)\n",
    "\n",
    "    # Handle cases where the image might have a different extension\n",
    "    if not os.path.exists(src_path):\n",
    "        src_path_jpeg = os.path.join(image_dir, image_name_no_ext + \".jpeg\")\n",
    "        if os.path.exists(src_path_jpeg):\n",
    "            src_path = src_path_jpeg\n",
    "            image_name = image_name_no_ext + \".jpeg\" # Update the filename for output\n",
    "        else:\n",
    "            print(f\"Warning: {image_name_no_ext} (with .jpg/.jpeg extensions) not found in {image_dir}\")\n",
    "            error_count += 1\n",
    "            continue\n",
    "        \n",
    "    img_bgr = cv2.imread(src_path, cv2.IMREAD_COLOR)\n",
    "    \n",
    "    if img_bgr is None:\n",
    "        print(f\"Error reading {src_path}\")\n",
    "        error_count += 1\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # 1. Convert to Grayscale\n",
    "        img_cv2_gray = convert_to_grayscale(img_bgr)\n",
    "\n",
    "        # 2. Segment the fundus, create the mask, and get the bounding box\n",
    "        fundus_mask, fundus_bbox = segment_fundus_and_create_mask(img_cv2_gray.copy(), image_name)\n",
    "\n",
    "        if DEBUG_SAVE_INTERMEDIATE:\n",
    "            cv2.imwrite(os.path.join(DEBUG_OUTPUT_DIR, f\"{image_name_no_ext}_0_gray.png\"), img_cv2_gray)\n",
    "            cv2.imwrite(os.path.join(DEBUG_OUTPUT_DIR, f\"{image_name_no_ext}_1_mask.png\"), fundus_mask)\n",
    "\n",
    "        # 3. Apply CLAHE, Gaussian Blur, and Median Filter to the grayscale image\n",
    "        img_clahe = apply_clahe(img_cv2_gray)\n",
    "        img_gaussian_blurred = apply_gaussian_blur(img_clahe)\n",
    "        img_median_filtered = apply_median_filter(img_gaussian_blurred)\n",
    "        fully_processed_gray_data = img_median_filtered\n",
    "\n",
    "        if DEBUG_SAVE_INTERMEDIATE:\n",
    "             cv2.imwrite(os.path.join(DEBUG_OUTPUT_DIR, f\"{image_name_no_ext}_2_fully_processed_gray.png\"), fully_processed_gray_data)\n",
    "\n",
    "        # 4. Apply the mask to black out the background of the processed image\n",
    "        masked_processed_fundus_cv2 = cv2.bitwise_and(fully_processed_gray_data, fully_processed_gray_data, mask=fundus_mask)\n",
    "\n",
    "        if DEBUG_SAVE_INTERMEDIATE:\n",
    "            cv2.imwrite(os.path.join(DEBUG_OUTPUT_DIR, f\"{image_name_no_ext}_3_masked_fundus.png\"), masked_processed_fundus_cv2)\n",
    "\n",
    "        # --- Fundus Size Normalization ---\n",
    "        if fundus_bbox:\n",
    "            x, y, w_bbox, h_bbox = fundus_bbox\n",
    "            if w_bbox > 0 and h_bbox > 0:\n",
    "                # Crop the masked fundus using the bounding box\n",
    "                cropped_fundus_cv2 = masked_processed_fundus_cv2[y:y+h_bbox, x:x+w_bbox]\n",
    "\n",
    "                if DEBUG_SAVE_INTERMEDIATE:\n",
    "                    cv2.imwrite(os.path.join(DEBUG_OUTPUT_DIR, f\"{image_name_no_ext}_4_cropped_fundus.png\"), cropped_fundus_cv2)\n",
    "\n",
    "                # Calculate the new dimensions for the cropped fundus\n",
    "                target_max_dim_px = int(max(FINAL_IMAGE_SIZE) * FUNDUS_TARGET_SCALE_FACTOR)\n",
    "                \n",
    "                current_max_dim_bbox = max(w_bbox, h_bbox)\n",
    "                scale_ratio = target_max_dim_px / current_max_dim_bbox if current_max_dim_bbox > 0 else 1\n",
    "                \n",
    "                new_w = int(w_bbox * scale_ratio)\n",
    "                new_h = int(h_bbox * scale_ratio)\n",
    "                \n",
    "                # Ensure the new dimensions are at least 1x1\n",
    "                new_w = max(1, new_w)\n",
    "                new_h = max(1, new_h)\n",
    "\n",
    "                interpolation = cv2.INTER_AREA if scale_ratio < 1 else cv2.INTER_CUBIC\n",
    "                resized_cropped_fundus_cv2 = cv2.resize(cropped_fundus_cv2, (new_w, new_h), interpolation=interpolation)\n",
    "                \n",
    "                # Convert the normalized and resized fundus to a PIL image\n",
    "                image_to_letterbox_pil = cv2_to_pil_grayscale(resized_cropped_fundus_cv2)\n",
    "\n",
    "                if DEBUG_SAVE_INTERMEDIATE:\n",
    "                    image_to_letterbox_pil.save(os.path.join(DEBUG_OUTPUT_DIR, f\"{image_name_no_ext}_5_resized_cropped_fundus.png\"))\n",
    "            else:\n",
    "                # Invalid bounding box (e.g., width or height is 0)\n",
    "                print(f\"Warning: Invalid fundus bounding box for {image_name}. The image will be black.\")\n",
    "                image_to_letterbox_pil = Image.new('L', (1,1), 0) # Small placeholder image to be letterboxed\n",
    "                null_bbox_count +=1\n",
    "        else:\n",
    "            # No bounding box found (no contour)\n",
    "            print(f\"Warning: No fundus bounding box for {image_name}. The image will be black.\")\n",
    "            image_to_letterbox_pil = Image.new('L', (1,1), 0) # Placeholder image\n",
    "            null_bbox_count +=1\n",
    "            \n",
    "        # 5. Letterbox: place the image (now the normalized fundus) into a 512x512 canvas\n",
    "        #    The padding color is 0 (black) because the fundus background is already black.\n",
    "        letterboxed_img_pil = letterbox_image(image_to_letterbox_pil, FINAL_IMAGE_SIZE, padding_color=0) \n",
    "        \n",
    "        # 6. Convert back to a NumPy array (CV2) for saving\n",
    "        final_img_to_save = pil_to_cv2_grayscale(letterboxed_img_pil)\n",
    "        \n",
    "        # 7. Save the processed image\n",
    "        output_filename = os.path.splitext(image_name)[0] + '.png'\n",
    "        output_path = os.path.join(output_class_path, output_filename)\n",
    "        cv2.imwrite(output_path, final_img_to_save)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_name}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc() # Print the full traceback for easier debugging\n",
    "        error_count += 1\n",
    "        continue\n",
    "\n",
    "print(f\"Number of images that could not be read or had processing errors: {error_count}\")\n",
    "print(f\"Number of images with null or invalid fundus bounding box: {null_bbox_count}\")\n",
    "print(\"Splitting and preprocessing complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4812671a-49f5-47f3-bd53-f49b0a152dec",
   "metadata": {},
   "source": [
    "## DeepDRiD Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc9196a-de2f-4cfb-884d-43dd45e059f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- File and folder paths ---\n",
    "csv_path = '/home/jupyter-sdm/GENITO/DATASETS/3_DeepDRiD/regular-fundus-validation.csv'\n",
    "image_dir = '/home/jupyter-sdm/GENITO/DATASETS/3_DeepDRiD/Validation'\n",
    "final_output_dir = \"/home/jupyter-sdm/GENITO/LAVORO_COMPLETO/Dataset_resize/3_DeepDRiD\"\n",
    "\n",
    "file_extension = \".jpg\"\n",
    "column_class_name = 'patient_DR_Level'\n",
    "colum_image_name = 'image_id'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(csv_path)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: CSV file not found at {csv_path}\")\n",
    "    exit()\n",
    "\n",
    "# Create output directories for each class\n",
    "classes = df[column_class_name].unique()\n",
    "for cls in classes:\n",
    "    class_output_path = os.path.join(final_output_dir, str(cls))\n",
    "    os.makedirs(class_output_path, exist_ok=True)\n",
    "\n",
    "error_count = 0\n",
    "null_bbox_count = 0\n",
    "\n",
    "for _, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Processing Images\", ncols=100, ascii=True):\n",
    "    image_name_no_ext = row[colum_image_name]\n",
    "    image_name = image_name_no_ext + file_extension # Will be updated if a .jpeg is found\n",
    "    image_class = str(row[column_class_name])\n",
    "    src_path = os.path.join(image_dir, image_name_no_ext + file_extension) # Try .jpg first\n",
    "    output_class_path = os.path.join(final_output_dir, image_class)\n",
    "\n",
    "    # Handle cases where the image might have a different extension\n",
    "    if not os.path.exists(src_path):\n",
    "        src_path_jpeg = os.path.join(image_dir, image_name_no_ext + \".jpeg\")\n",
    "        if os.path.exists(src_path_jpeg):\n",
    "            src_path = src_path_jpeg\n",
    "            image_name = image_name_no_ext + \".jpeg\" # Update the filename for output\n",
    "        else:\n",
    "            print(f\"Warning: {image_name_no_ext} (with .jpg/.jpeg extensions) not found in {image_dir}\")\n",
    "            error_count += 1\n",
    "            continue\n",
    "        \n",
    "    img_bgr = cv2.imread(src_path, cv2.IMREAD_COLOR)\n",
    "    \n",
    "    if img_bgr is None:\n",
    "        print(f\"Error reading {src_path}\")\n",
    "        error_count += 1\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # 1. Convert to Grayscale\n",
    "        img_cv2_gray = convert_to_grayscale(img_bgr)\n",
    "\n",
    "        # 2. Segment the fundus, create the mask, and get the bounding box\n",
    "        fundus_mask, fundus_bbox = segment_fundus_and_create_mask(img_cv2_gray.copy(), image_name)\n",
    "\n",
    "        if DEBUG_SAVE_INTERMEDIATE:\n",
    "            cv2.imwrite(os.path.join(DEBUG_OUTPUT_DIR, f\"{image_name_no_ext}_0_gray.png\"), img_cv2_gray)\n",
    "            cv2.imwrite(os.path.join(DEBUG_OUTPUT_DIR, f\"{image_name_no_ext}_1_mask.png\"), fundus_mask)\n",
    "\n",
    "        # 3. Apply CLAHE, Gaussian Blur, and Median Filter to the grayscale image\n",
    "        img_clahe = apply_clahe(img_cv2_gray)\n",
    "        img_gaussian_blurred = apply_gaussian_blur(img_clahe)\n",
    "        img_median_filtered = apply_median_filter(img_gaussian_blurred)\n",
    "        fully_processed_gray_data = img_median_filtered\n",
    "\n",
    "        if DEBUG_SAVE_INTERMEDIATE:\n",
    "             cv2.imwrite(os.path.join(DEBUG_OUTPUT_DIR, f\"{image_name_no_ext}_2_fully_processed_gray.png\"), fully_processed_gray_data)\n",
    "\n",
    "        # 4. Apply the mask to black out the background of the processed image\n",
    "        masked_processed_fundus_cv2 = cv2.bitwise_and(fully_processed_gray_data, fully_processed_gray_data, mask=fundus_mask)\n",
    "\n",
    "        if DEBUG_SAVE_INTERMEDIATE:\n",
    "            cv2.imwrite(os.path.join(DEBUG_OUTPUT_DIR, f\"{image_name_no_ext}_3_masked_fundus.png\"), masked_processed_fundus_cv2)\n",
    "\n",
    "        # --- Fundus Size Normalization ---\n",
    "        if fundus_bbox:\n",
    "            x, y, w_bbox, h_bbox = fundus_bbox\n",
    "            if w_bbox > 0 and h_bbox > 0:\n",
    "                # Crop the masked fundus using the bounding box\n",
    "                cropped_fundus_cv2 = masked_processed_fundus_cv2[y:y+h_bbox, x:x+w_bbox]\n",
    "\n",
    "                if DEBUG_SAVE_INTERMEDIATE:\n",
    "                    cv2.imwrite(os.path.join(DEBUG_OUTPUT_DIR, f\"{image_name_no_ext}_4_cropped_fundus.png\"), cropped_fundus_cv2)\n",
    "\n",
    "                # Calculate the new dimensions for the cropped fundus\n",
    "                target_max_dim_px = int(max(FINAL_IMAGE_SIZE) * FUNDUS_TARGET_SCALE_FACTOR)\n",
    "                \n",
    "                current_max_dim_bbox = max(w_bbox, h_bbox)\n",
    "                scale_ratio = target_max_dim_px / current_max_dim_bbox if current_max_dim_bbox > 0 else 1\n",
    "                \n",
    "                new_w = int(w_bbox * scale_ratio)\n",
    "                new_h = int(h_bbox * scale_ratio)\n",
    "                \n",
    "                # Ensure the new dimensions are at least 1x1\n",
    "                new_w = max(1, new_w)\n",
    "                new_h = max(1, new_h)\n",
    "\n",
    "                interpolation = cv2.INTER_AREA if scale_ratio < 1 else cv2.INTER_CUBIC\n",
    "                resized_cropped_fundus_cv2 = cv2.resize(cropped_fundus_cv2, (new_w, new_h), interpolation=interpolation)\n",
    "                \n",
    "                # Convert the normalized and resized fundus to a PIL image\n",
    "                image_to_letterbox_pil = cv2_to_pil_grayscale(resized_cropped_fundus_cv2)\n",
    "\n",
    "                if DEBUG_SAVE_INTERMEDIATE:\n",
    "                    image_to_letterbox_pil.save(os.path.join(DEBUG_OUTPUT_DIR, f\"{image_name_no_ext}_5_resized_cropped_fundus.png\"))\n",
    "            else:\n",
    "                # Invalid bounding box (e.g., width or height is 0)\n",
    "                print(f\"Warning: Invalid fundus bounding box for {image_name}. The image will be black.\")\n",
    "                image_to_letterbox_pil = Image.new('L', (1,1), 0) # Small placeholder image to be letterboxed\n",
    "                null_bbox_count +=1\n",
    "        else:\n",
    "            # No bounding box found (no contour)\n",
    "            print(f\"Warning: No fundus bounding box for {image_name}. The image will be black.\")\n",
    "            image_to_letterbox_pil = Image.new('L', (1,1), 0) # Placeholder image\n",
    "            null_bbox_count +=1\n",
    "            \n",
    "        # 5. Letterbox: place the image (now the normalized fundus) into a 512x512 canvas\n",
    "        #    The padding color is 0 (black) because the fundus background is already black.\n",
    "        letterboxed_img_pil = letterbox_image(image_to_letterbox_pil, FINAL_IMAGE_SIZE, padding_color=0) \n",
    "        \n",
    "        # 6. Convert back to a NumPy array (CV2) for saving\n",
    "        final_img_to_save = pil_to_cv2_grayscale(letterboxed_img_pil)\n",
    "        \n",
    "        # 7. Save the processed image\n",
    "        output_filename = os.path.splitext(image_name)[0] + '.png'\n",
    "        output_path = os.path.join(output_class_path, output_filename)\n",
    "        cv2.imwrite(output_path, final_img_to_save)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_name}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc() # Print the full traceback for easier debugging\n",
    "        error_count += 1\n",
    "        continue\n",
    "\n",
    "print(f\"Number of images that could not be read or had processing errors: {error_count}\")\n",
    "print(f\"Number of images with null or invalid fundus bounding box: {null_bbox_count}\")\n",
    "print(\"Splitting and preprocessing complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c78080-7886-46fd-b28b-377854a22975",
   "metadata": {},
   "source": [
    "## DeepDRiD Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4224f7-80b2-4610-aa5c-72fd3b09da57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- File and folder paths ---\n",
    "csv_path = '/home/jupyter-sdm/GENITO/DATASETS/3_DeepDRiD/test1.csv'\n",
    "image_dir = '/home/jupyter-sdm/GENITO/DATASETS/3_DeepDRiD/test'\n",
    "final_output_dir = \"/home/jupyter-sdm/GENITO/LAVORO_COMPLETO/Dataset_resize/3_DeepDRiD\"\n",
    "\n",
    "file_extension = \".jpg\"\n",
    "column_class_name = 'DR_Levels'\n",
    "colum_image_name = 'image_id'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(csv_path)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: CSV file not found at {csv_path}\")\n",
    "    exit()\n",
    "\n",
    "# Create output directories for each class\n",
    "classes = df[column_class_name].unique()\n",
    "for cls in classes:\n",
    "    class_output_path = os.path.join(final_output_dir, str(cls))\n",
    "    os.makedirs(class_output_path, exist_ok=True)\n",
    "\n",
    "error_count = 0\n",
    "null_bbox_count = 0\n",
    "\n",
    "for _, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Processing Images\", ncols=100, ascii=True):\n",
    "    image_name_no_ext = row[colum_image_name]\n",
    "    image_name = image_name_no_ext + file_extension # Will be updated if a .jpeg is found\n",
    "    image_class = str(row[column_class_name])\n",
    "    src_path = os.path.join(image_dir, image_name_no_ext + file_extension) # Try .jpg first\n",
    "    output_class_path = os.path.join(final_output_dir, image_class)\n",
    "\n",
    "    # Handle cases where the image might have a different extension\n",
    "    if not os.path.exists(src_path):\n",
    "        src_path_jpeg = os.path.join(image_dir, image_name_no_ext + \".jpeg\")\n",
    "        if os.path.exists(src_path_jpeg):\n",
    "            src_path = src_path_jpeg\n",
    "            image_name = image_name_no_ext + \".jpeg\" # Update the filename for output\n",
    "        else:\n",
    "            print(f\"Warning: {image_name_no_ext} (with .jpg/.jpeg extensions) not found in {image_dir}\")\n",
    "            error_count += 1\n",
    "            continue\n",
    "        \n",
    "    img_bgr = cv2.imread(src_path, cv2.IMREAD_COLOR)\n",
    "    \n",
    "    if img_bgr is None:\n",
    "        print(f\"Error reading {src_path}\")\n",
    "        error_count += 1\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # 1. Convert to Grayscale\n",
    "        img_cv2_gray = convert_to_grayscale(img_bgr)\n",
    "\n",
    "        # 2. Segment the fundus, create the mask, and get the bounding box\n",
    "        fundus_mask, fundus_bbox = segment_fundus_and_create_mask(img_cv2_gray.copy(), image_name)\n",
    "\n",
    "        if DEBUG_SAVE_INTERMEDIATE:\n",
    "            cv2.imwrite(os.path.join(DEBUG_OUTPUT_DIR, f\"{image_name_no_ext}_0_gray.png\"), img_cv2_gray)\n",
    "            cv2.imwrite(os.path.join(DEBUG_OUTPUT_DIR, f\"{image_name_no_ext}_1_mask.png\"), fundus_mask)\n",
    "\n",
    "        # 3. Apply CLAHE, Gaussian Blur, and Median Filter to the grayscale image\n",
    "        img_clahe = apply_clahe(img_cv2_gray)\n",
    "        img_gaussian_blurred = apply_gaussian_blur(img_clahe)\n",
    "        img_median_filtered = apply_median_filter(img_gaussian_blurred)\n",
    "        fully_processed_gray_data = img_median_filtered\n",
    "\n",
    "        if DEBUG_SAVE_INTERMEDIATE:\n",
    "             cv2.imwrite(os.path.join(DEBUG_OUTPUT_DIR, f\"{image_name_no_ext}_2_fully_processed_gray.png\"), fully_processed_gray_data)\n",
    "\n",
    "        # 4. Apply the mask to black out the background of the processed image\n",
    "        masked_processed_fundus_cv2 = cv2.bitwise_and(fully_processed_gray_data, fully_processed_gray_data, mask=fundus_mask)\n",
    "\n",
    "        if DEBUG_SAVE_INTERMEDIATE:\n",
    "            cv2.imwrite(os.path.join(DEBUG_OUTPUT_DIR, f\"{image_name_no_ext}_3_masked_fundus.png\"), masked_processed_fundus_cv2)\n",
    "\n",
    "        # --- Fundus Size Normalization ---\n",
    "        if fundus_bbox:\n",
    "            x, y, w_bbox, h_bbox = fundus_bbox\n",
    "            if w_bbox > 0 and h_bbox > 0:\n",
    "                # Crop the masked fundus using the bounding box\n",
    "                cropped_fundus_cv2 = masked_processed_fundus_cv2[y:y+h_bbox, x:x+w_bbox]\n",
    "\n",
    "                if DEBUG_SAVE_INTERMEDIATE:\n",
    "                    cv2.imwrite(os.path.join(DEBUG_OUTPUT_DIR, f\"{image_name_no_ext}_4_cropped_fundus.png\"), cropped_fundus_cv2)\n",
    "\n",
    "                # Calculate the new dimensions for the cropped fundus\n",
    "                target_max_dim_px = int(max(FINAL_IMAGE_SIZE) * FUNDUS_TARGET_SCALE_FACTOR)\n",
    "                \n",
    "                current_max_dim_bbox = max(w_bbox, h_bbox)\n",
    "                scale_ratio = target_max_dim_px / current_max_dim_bbox if current_max_dim_bbox > 0 else 1\n",
    "                \n",
    "                new_w = int(w_bbox * scale_ratio)\n",
    "                new_h = int(h_bbox * scale_ratio)\n",
    "                \n",
    "                # Ensure the new dimensions are at least 1x1\n",
    "                new_w = max(1, new_w)\n",
    "                new_h = max(1, new_h)\n",
    "\n",
    "                interpolation = cv2.INTER_AREA if scale_ratio < 1 else cv2.INTER_CUBIC\n",
    "                resized_cropped_fundus_cv2 = cv2.resize(cropped_fundus_cv2, (new_w, new_h), interpolation=interpolation)\n",
    "                \n",
    "                # Convert the normalized and resized fundus to a PIL image\n",
    "                image_to_letterbox_pil = cv2_to_pil_grayscale(resized_cropped_fundus_cv2)\n",
    "\n",
    "                if DEBUG_SAVE_INTERMEDIATE:\n",
    "                    image_to_letterbox_pil.save(os.path.join(DEBUG_OUTPUT_DIR, f\"{image_name_no_ext}_5_resized_cropped_fundus.png\"))\n",
    "            else:\n",
    "                # Invalid bounding box (e.g., width or height is 0)\n",
    "                print(f\"Warning: Invalid fundus bounding box for {image_name}. The image will be black.\")\n",
    "                image_to_letterbox_pil = Image.new('L', (1,1), 0) # Small placeholder image to be letterboxed\n",
    "                null_bbox_count +=1\n",
    "        else:\n",
    "            # No bounding box found (no contour)\n",
    "            print(f\"Warning: No fundus bounding box for {image_name}. The image will be black.\")\n",
    "            image_to_letterbox_pil = Image.new('L', (1,1), 0) # Placeholder image\n",
    "            null_bbox_count +=1\n",
    "            \n",
    "        # 5. Letterbox: place the image (now the normalized fundus) into a 512x512 canvas\n",
    "        #    The padding color is 0 (black) because the fundus background is already black.\n",
    "        letterboxed_img_pil = letterbox_image(image_to_letterbox_pil, FINAL_IMAGE_SIZE, padding_color=0) \n",
    "        \n",
    "        # 6. Convert back to a NumPy array (CV2) for saving\n",
    "        final_img_to_save = pil_to_cv2_grayscale(letterboxed_img_pil)\n",
    "        \n",
    "        # 7. Save the processed image\n",
    "        output_filename = os.path.splitext(image_name)[0] + '.png'\n",
    "        output_path = os.path.join(output_class_path, output_filename)\n",
    "        cv2.imwrite(output_path, final_img_to_save)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_name}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc() # Print the full traceback for easier debugging\n",
    "        error_count += 1\n",
    "        continue\n",
    "\n",
    "print(f\"Number of images that could not be read or had processing errors: {error_count}\")\n",
    "print(f\"Number of images with null or invalid fundus bounding box: {null_bbox_count}\")\n",
    "print(\"Splitting and preprocessing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80ae174-122f-4fbc-8a64-0452fca05e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DeepDrid Check\n",
    "deepdrid_base_path = \"/home/jupyter-sdm/GENITO/LAVORO_COMPLETO/Dataset_resize/3_DeepDRiD\"\n",
    "total_images_deepdrid = sum(len(os.listdir(os.path.join(deepdrid_base_path, str(i)))) for i in range(5))\n",
    "\n",
    "print(f\"Total number of images in the DeepDrid dataset: {total_images_deepdrid}\")\n",
    "\n",
    "for cls in range(5):\n",
    "    num_images = len(os.listdir(os.path.join(deepdrid_base_path, str(cls))))\n",
    "    print(f\"Class {cls}: {num_images} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2edfd9-a379-4aac-a02c-2ae250ebf834",
   "metadata": {},
   "source": [
    "# 4 Messidor2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4f72a6-7880-49b9-85b2-4b87e5358ba6",
   "metadata": {},
   "source": [
    "## Messidor2 Training Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc8ccff-da87-41d1-9ee4-6538685af590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- File and folder paths ---\n",
    "csv_path = '/home/jupyter-sdm/GENITO/DATASETS/4_MESSIDOR2/messidor_data.csv'\n",
    "image_dir = '/home/jupyter-sdm/GENITO/DATASETS/4_MESSIDOR2/images'\n",
    "final_output_dir = \"/home/jupyter-sdm/GENITO/LAVORO_COMPLETO/Dataset_resize/4_Messidor2/\"\n",
    "\n",
    "column_class_name = 'diagnosis'\n",
    "colum_image_name = 'id_code'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(csv_path)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: CSV file not found at {csv_path}\")\n",
    "    exit()\n",
    "\n",
    "# Create output directories for each class\n",
    "classes = df[column_class_name].unique()\n",
    "for cls in classes:\n",
    "    class_output_path = os.path.join(final_output_dir, str(cls))\n",
    "    os.makedirs(class_output_path, exist_ok=True)\n",
    "\n",
    "error_count = 0\n",
    "null_bbox_count = 0\n",
    "\n",
    "for _, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Processing Images\", ncols=100, ascii=True):\n",
    "    # Assuming 'id_code' in the CSV contains the full filename with extension\n",
    "    image_filename = row[colum_image_name] \n",
    "    image_class = str(row[column_class_name])\n",
    "    src_path = os.path.join(image_dir, image_filename)\n",
    "    output_class_path = os.path.join(final_output_dir, image_class)\n",
    "\n",
    "    # Fallback check if the primary file path doesn't exist\n",
    "    if not os.path.exists(src_path):\n",
    "        # This fallback logic might be specific to the dataset's structure\n",
    "        src_path_jpeg = os.path.join(image_dir, image_filename + \".jpeg\")\n",
    "        if os.path.exists(src_path_jpeg):\n",
    "            src_path = src_path_jpeg\n",
    "            image_filename = image_filename + \".jpeg\" # Update the filename for output\n",
    "        else:\n",
    "            print(f\"Warning: {image_filename} not found in {image_dir}\")\n",
    "            error_count += 1\n",
    "            continue\n",
    "        \n",
    "    img_bgr = cv2.imread(src_path, cv2.IMREAD_COLOR)\n",
    "    \n",
    "    if img_bgr is None:\n",
    "        print(f\"Error reading {src_path}\")\n",
    "        error_count += 1\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # 1. Convert to Grayscale\n",
    "        img_cv2_gray = convert_to_grayscale(img_bgr)\n",
    "\n",
    "        # 2. Segment the fundus, create the mask, and get the bounding box\n",
    "        fundus_mask, fundus_bbox = segment_fundus_and_create_mask(img_cv2_gray.copy(), image_filename)\n",
    "\n",
    "        if DEBUG_SAVE_INTERMEDIATE:\n",
    "            debug_name = os.path.splitext(image_filename)[0]\n",
    "            cv2.imwrite(os.path.join(DEBUG_OUTPUT_DIR, f\"{debug_name}_0_gray.png\"), img_cv2_gray)\n",
    "            cv2.imwrite(os.path.join(DEBUG_OUTPUT_DIR, f\"{debug_name}_1_mask.png\"), fundus_mask)\n",
    "\n",
    "        # 3. Apply CLAHE, Gaussian Blur, and Median Filter to the grayscale image\n",
    "        img_clahe = apply_clahe(img_cv2_gray)\n",
    "        img_gaussian_blurred = apply_gaussian_blur(img_clahe)\n",
    "        img_median_filtered = apply_median_filter(img_gaussian_blurred)\n",
    "        fully_processed_gray_data = img_median_filtered\n",
    "\n",
    "        if DEBUG_SAVE_INTERMEDIATE:\n",
    "             cv2.imwrite(os.path.join(DEBUG_OUTPUT_DIR, f\"{debug_name}_2_fully_processed_gray.png\"), fully_processed_gray_data)\n",
    "\n",
    "        # 4. Apply the mask to black out the background of the processed image\n",
    "        masked_processed_fundus_cv2 = cv2.bitwise_and(fully_processed_gray_data, fully_processed_gray_data, mask=fundus_mask)\n",
    "\n",
    "        if DEBUG_SAVE_INTERMEDIATE:\n",
    "            cv2.imwrite(os.path.join(DEBUG_OUTPUT_DIR, f\"{debug_name}_3_masked_fundus.png\"), masked_processed_fundus_cv2)\n",
    "\n",
    "        # --- Fundus Size Normalization ---\n",
    "        if fundus_bbox:\n",
    "            x, y, w_bbox, h_bbox = fundus_bbox\n",
    "            if w_bbox > 0 and h_bbox > 0:\n",
    "                # Crop the masked fundus using the bounding box\n",
    "                cropped_fundus_cv2 = masked_processed_fundus_cv2[y:y+h_bbox, x:x+w_bbox]\n",
    "\n",
    "                if DEBUG_SAVE_INTERMEDIATE:\n",
    "                    cv2.imwrite(os.path.join(DEBUG_OUTPUT_DIR, f\"{debug_name}_4_cropped_fundus.png\"), cropped_fundus_cv2)\n",
    "\n",
    "                # Calculate the new dimensions for the cropped fundus\n",
    "                target_max_dim_px = int(max(FINAL_IMAGE_SIZE) * FUNDUS_TARGET_SCALE_FACTOR)\n",
    "                \n",
    "                current_max_dim_bbox = max(w_bbox, h_bbox)\n",
    "                scale_ratio = target_max_dim_px / current_max_dim_bbox if current_max_dim_bbox > 0 else 1\n",
    "                \n",
    "                new_w = int(w_bbox * scale_ratio)\n",
    "                new_h = int(h_bbox * scale_ratio)\n",
    "                \n",
    "                # Ensure the new dimensions are at least 1x1\n",
    "                new_w = max(1, new_w)\n",
    "                new_h = max(1, new_h)\n",
    "\n",
    "                interpolation = cv2.INTER_AREA if scale_ratio < 1 else cv2.INTER_CUBIC\n",
    "                resized_cropped_fundus_cv2 = cv2.resize(cropped_fundus_cv2, (new_w, new_h), interpolation=interpolation)\n",
    "                \n",
    "                # Convert the normalized and resized fundus to a PIL image\n",
    "                image_to_letterbox_pil = cv2_to_pil_grayscale(resized_cropped_fundus_cv2)\n",
    "\n",
    "                if DEBUG_SAVE_INTERMEDIATE:\n",
    "                    image_to_letterbox_pil.save(os.path.join(DEBUG_OUTPUT_DIR, f\"{debug_name}_5_resized_cropped_fundus.png\"))\n",
    "            else:\n",
    "                # Invalid bounding box (e.g., width or height is 0)\n",
    "                print(f\"Warning: Invalid fundus bounding box for {image_filename}. The image will be black.\")\n",
    "                image_to_letterbox_pil = Image.new('L', (1,1), 0) # Small placeholder image to be letterboxed\n",
    "                null_bbox_count +=1\n",
    "        else:\n",
    "            # No bounding box found (no contour)\n",
    "            print(f\"Warning: No fundus bounding box for {image_filename}. The image will be black.\")\n",
    "            image_to_letterbox_pil = Image.new('L', (1,1), 0) # Placeholder image\n",
    "            null_bbox_count +=1\n",
    "            \n",
    "        # 5. Letterbox: place the image (now the normalized fundus) into a 512x512 canvas\n",
    "        #    The padding color is 0 (black) because the fundus background is already black.\n",
    "        letterboxed_img_pil = letterbox_image(image_to_letterbox_pil, FINAL_IMAGE_SIZE, padding_color=0) \n",
    "        \n",
    "        # 6. Convert back to a NumPy array (CV2) for saving\n",
    "        final_img_to_save = pil_to_cv2_grayscale(letterboxed_img_pil)\n",
    "        \n",
    "        # 7. Save the processed image\n",
    "        output_filename = os.path.splitext(image_filename)[0] + '.png'\n",
    "        output_path = os.path.join(output_class_path, output_filename)\n",
    "        cv2.imwrite(output_path, final_img_to_save)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_filename}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc() # Print the full traceback for easier debugging\n",
    "        error_count += 1\n",
    "        continue\n",
    "\n",
    "print(f\"Number of images that could not be read or had processing errors: {error_count}\")\n",
    "print(f\"Number of images with null or invalid fundus bounding box: {null_bbox_count}\")\n",
    "print(\"Splitting and preprocessing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adb4586-6ff9-401c-97f0-d1d16e8a33f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Messidor-2 Check\n",
    "messidor_base_path = \"/home/jupyter-sdm/GENITO/LAVORO_COMPLETO/Dataset_resize/4_Messidor2\"\n",
    "total_images_messidor = sum(len(os.listdir(os.path.join(messidor_base_path, str(i)))) for i in range(5))\n",
    "\n",
    "print(f\"Total number of images in the Messidor-2 dataset: {total_images_messidor}\")\n",
    "\n",
    "for cls in range(5):\n",
    "    num_images = len(os.listdir(os.path.join(messidor_base_path, str(cls))))\n",
    "    print(f\"Class {cls}: {num_images} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48218d86-8cbb-46a1-af95-e93710cd253c",
   "metadata": {},
   "source": [
    "# 5 FGADR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c38c87-7eff-4805-9fbb-5c85f5b012d9",
   "metadata": {},
   "source": [
    "## FGADR Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ecb89e-b35e-4748-8852-86010acc8784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- File and folder paths ---\n",
    "csv_path = '/home/jupyter-sdm/GENITO/DATASETS/5_FGADR/Seg-set/DR_Seg_Grading_Label.csv'\n",
    "image_dir = '/home/jupyter-sdm/GENITO/DATASETS/5_FGADR/Seg-set/Original_Images'\n",
    "final_output_dir = \"/home/jupyter-sdm/GENITO/LAVORO_COMPLETO/Dataset_resize/5_FGADR/\"\n",
    "\n",
    "column_class_name = 'grade'\n",
    "colum_image_name = 'image'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(csv_path)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: CSV file not found at {csv_path}\")\n",
    "    exit()\n",
    "\n",
    "# Create output directories for each class\n",
    "classes = df[column_class_name].unique()\n",
    "for cls in classes:\n",
    "    class_output_path = os.path.join(final_output_dir, str(cls))\n",
    "    os.makedirs(class_output_path, exist_ok=True)\n",
    "\n",
    "error_count = 0\n",
    "null_bbox_count = 0\n",
    "\n",
    "for _, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Processing Images\", ncols=100, ascii=True):\n",
    "    # The 'image' column in the CSV should contain the full filename with its extension\n",
    "    image_filename = row[colum_image_name]\n",
    "    image_class = str(row[column_class_name])\n",
    "    src_path = os.path.join(image_dir, image_filename)\n",
    "    output_class_path = os.path.join(final_output_dir, image_class)\n",
    "\n",
    "    # Fallback check if the primary file path doesn't exist\n",
    "    if not os.path.exists(src_path):\n",
    "        src_path_jpeg = os.path.join(image_dir, image_filename + \".jpeg\")\n",
    "        if os.path.exists(src_path_jpeg):\n",
    "            src_path = src_path_jpeg\n",
    "            image_filename = image_filename + \".jpeg\" # Update the filename for output\n",
    "        else:\n",
    "            print(f\"Warning: {image_filename} not found in {image_dir}\")\n",
    "            error_count += 1\n",
    "            continue\n",
    "        \n",
    "    img_bgr = cv2.imread(src_path, cv2.IMREAD_COLOR)\n",
    "    \n",
    "    if img_bgr is None:\n",
    "        print(f\"Error reading {src_path}\")\n",
    "        error_count += 1\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # 1. Convert to Grayscale\n",
    "        img_cv2_gray = convert_to_grayscale(img_bgr)\n",
    "\n",
    "        # 2. Segment the fundus, create the mask, and get the bounding box\n",
    "        fundus_mask, fundus_bbox = segment_fundus_and_create_mask(img_cv2_gray.copy(), image_filename)\n",
    "\n",
    "        if DEBUG_SAVE_INTERMEDIATE:\n",
    "            debug_name = os.path.splitext(image_filename)[0]\n",
    "            cv2.imwrite(os.path.join(DEBUG_OUTPUT_DIR, f\"{debug_name}_0_gray.png\"), img_cv2_gray)\n",
    "            cv2.imwrite(os.path.join(DEBUG_OUTPUT_DIR, f\"{debug_name}_1_mask.png\"), fundus_mask)\n",
    "\n",
    "        # 3. Apply CLAHE, Gaussian Blur, and Median Filter to the grayscale image\n",
    "        img_clahe = apply_clahe(img_cv2_gray)\n",
    "        img_gaussian_blurred = apply_gaussian_blur(img_clahe)\n",
    "        img_median_filtered = apply_median_filter(img_gaussian_blurred)\n",
    "        fully_processed_gray_data = img_median_filtered\n",
    "\n",
    "        if DEBUG_SAVE_INTERMEDIATE:\n",
    "             cv2.imwrite(os.path.join(DEBUG_OUTPUT_DIR, f\"{debug_name}_2_fully_processed_gray.png\"), fully_processed_gray_data)\n",
    "\n",
    "        # 4. Apply the mask to black out the background of the processed image\n",
    "        masked_processed_fundus_cv2 = cv2.bitwise_and(fully_processed_gray_data, fully_processed_gray_data, mask=fundus_mask)\n",
    "\n",
    "        if DEBUG_SAVE_INTERMEDIATE:\n",
    "            cv2.imwrite(os.path.join(DEBUG_OUTPUT_DIR, f\"{debug_name}_3_masked_fundus.png\"), masked_processed_fundus_cv2)\n",
    "\n",
    "        # --- Fundus Size Normalization ---\n",
    "        if fundus_bbox:\n",
    "            x, y, w_bbox, h_bbox = fundus_bbox\n",
    "            if w_bbox > 0 and h_bbox > 0:\n",
    "                # Crop the masked fundus using the bounding box\n",
    "                cropped_fundus_cv2 = masked_processed_fundus_cv2[y:y+h_bbox, x:x+w_bbox]\n",
    "\n",
    "                if DEBUG_SAVE_INTERMEDIATE:\n",
    "                    cv2.imwrite(os.path.join(DEBUG_OUTPUT_DIR, f\"{debug_name}_4_cropped_fundus.png\"), cropped_fundus_cv2)\n",
    "\n",
    "                # Calculate the new dimensions for the cropped fundus\n",
    "                target_max_dim_px = int(max(FINAL_IMAGE_SIZE) * FUNDUS_TARGET_SCALE_FACTOR)\n",
    "                \n",
    "                current_max_dim_bbox = max(w_bbox, h_bbox)\n",
    "                scale_ratio = target_max_dim_px / current_max_dim_bbox if current_max_dim_bbox > 0 else 1\n",
    "                \n",
    "                new_w = int(w_bbox * scale_ratio)\n",
    "                new_h = int(h_bbox * scale_ratio)\n",
    "                \n",
    "                # Ensure the new dimensions are at least 1x1\n",
    "                new_w = max(1, new_w)\n",
    "                new_h = max(1, new_h)\n",
    "\n",
    "                interpolation = cv2.INTER_AREA if scale_ratio < 1 else cv2.INTER_CUBIC\n",
    "                resized_cropped_fundus_cv2 = cv2.resize(cropped_fundus_cv2, (new_w, new_h), interpolation=interpolation)\n",
    "                \n",
    "                # Convert the normalized and resized fundus to a PIL image\n",
    "                image_to_letterbox_pil = cv2_to_pil_grayscale(resized_cropped_fundus_cv2)\n",
    "\n",
    "                if DEBUG_SAVE_INTERMEDIATE:\n",
    "                    image_to_letterbox_pil.save(os.path.join(DEBUG_OUTPUT_DIR, f\"{debug_name}_5_resized_cropped_fundus.png\"))\n",
    "            else:\n",
    "                # Invalid bounding box (e.g., width or height is 0)\n",
    "                print(f\"Warning: Invalid fundus bounding box for {image_filename}. The image will be black.\")\n",
    "                image_to_letterbox_pil = Image.new('L', (1,1), 0) # Small placeholder image to be letterboxed\n",
    "                null_bbox_count +=1\n",
    "        else:\n",
    "            # No bounding box found (no contour)\n",
    "            print(f\"Warning: No fundus bounding box for {image_filename}. The image will be black.\")\n",
    "            image_to_letterbox_pil = Image.new('L', (1,1), 0) # Placeholder image\n",
    "            null_bbox_count +=1\n",
    "            \n",
    "        # 5. Letterbox: place the image (now the normalized fundus) into a 512x512 canvas\n",
    "        #    The padding color is 0 (black) because the fundus background is already black.\n",
    "        letterboxed_img_pil = letterbox_image(image_to_letterbox_pil, FINAL_IMAGE_SIZE, padding_color=0) \n",
    "        \n",
    "        # 6. Convert back to a NumPy array (CV2) for saving\n",
    "        final_img_to_save = pil_to_cv2_grayscale(letterboxed_img_pil)\n",
    "        \n",
    "        # 7. Save the processed image\n",
    "        output_filename = os.path.splitext(image_filename)[0] + '.png'\n",
    "        output_path = os.path.join(output_class_path, output_filename)\n",
    "        cv2.imwrite(output_path, final_img_to_save)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_filename}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc() # Print the full traceback for easier debugging\n",
    "        error_count += 1\n",
    "        continue\n",
    "\n",
    "print(f\"Number of images that could not be read or had processing errors: {error_count}\")\n",
    "print(f\"Number of images with null or invalid fundus bounding box: {null_bbox_count}\")\n",
    "print(\"Splitting and preprocessing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05bc984-58b5-4e63-8dff-1398b0eba0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## FGADR Check\n",
    "fgadr_base_path = \"/home/jupyter-sdm/GENITO/LAVORO_COMPLETO/Dataset_resize/5_FGADR\"\n",
    "total_images_fgadr = sum(len(os.listdir(os.path.join(fgadr_base_path, str(i)))) for i in range(5))\n",
    "\n",
    "print(f\"Total number of images in the FGADR dataset: {total_images_fgadr}\")\n",
    "\n",
    "for cls in range(5):\n",
    "    num_images = len(os.listdir(os.path.join(fgadr_base_path, str(cls))))\n",
    "    print(f\"Class {cls}: {num_images} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbdaf5b-00e5-4d61-900b-c9f23de5043f",
   "metadata": {},
   "source": [
    "# 6 RLDR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376c6a47-eacf-4904-ac14-a0493e8f5dac",
   "metadata": {},
   "source": [
    "## RLDR Training Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b78d519-6bd9-4e38-9c8c-dd20e73060ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percorsi file e cartelle\n",
    "csv_path = '/home/jupyter-sdm/GENITO/DATASETS/6_RLDR/retinal-lesions-v20191227/dr_grades.csv'  \n",
    "image_dir = '/home/jupyter-sdm/GENITO/DATASETS/6_RLDR/retinal-lesions-v20191227/images_896x896' \n",
    "final_output_dir = \"/home/jupyter-sdm/GENITO/LAVORO_COMPLETO/Dataset_resize/6_RLDR/\"\n",
    "\n",
    "file_extension = \".jpg\"\n",
    "column_class_name = 'our label'\n",
    "colum_image_name = 'image id'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(csv_path)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Errore: File CSV non trovato a {csv_path}\")\n",
    "    exit()\n",
    "\n",
    "classes = df[column_class_name].unique()\n",
    "for cls in classes:\n",
    "    class_output_path = os.path.join(final_output_dir, str(cls))\n",
    "    os.makedirs(class_output_path, exist_ok=True)\n",
    "\n",
    "conta_errate = 0\n",
    "conta_bbox_nulle = 0\n",
    "\n",
    "for _, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Processing\", ncols=100, ascii=True):\n",
    "    image_name_no_ext = row[colum_image_name]\n",
    "    image_name = image_name_no_ext + file_extension # Verr aggiornato se si trova .jpeg\n",
    "    image_class = str(row[column_class_name])\n",
    "    src_path = os.path.join(image_dir, image_name_no_ext + file_extension) # Prova prima .jpg\n",
    "    output_class_path = os.path.join(final_output_dir, image_class)\n",
    "\n",
    "    if not os.path.exists(src_path):\n",
    "        src_path_jpeg = os.path.join(image_dir, image_name_no_ext + \".jpeg\")\n",
    "        if os.path.exists(src_path_jpeg):\n",
    "            src_path = src_path_jpeg\n",
    "            image_name = image_name_no_ext + \".jpeg\" # Aggiorna il nome file per l'output\n",
    "        else:\n",
    "            print(f\"Attenzione: {image_name_no_ext} (con estensioni .jpg/.jpeg) non trovato in {image_dir}\")\n",
    "            conta_errate += 1\n",
    "            continue\n",
    "        \n",
    "    img_bgr = cv2.imread(src_path, cv2.IMREAD_COLOR)\n",
    "    \n",
    "    if img_bgr is None:\n",
    "        print(f\"Errore nella lettura di {src_path}\")\n",
    "        conta_errate += 1\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # 1. Converti in Scala di Grigi\n",
    "        img_cv2_gray = convert_to_grayscale(img_bgr)\n",
    "\n",
    "        # 2. Segmenta il fondo, crea la maschera e ottieni il bounding box\n",
    "        fundus_mask, fundus_bbox = segment_fundus_and_create_mask(img_cv2_gray.copy(), image_name)\n",
    "\n",
    "        if DEBUG_SAVE_INTERMEDIATE:\n",
    "            cv2.imwrite(os.path.join(DEBUG_OUTPUT_DIR, f\"{image_name_no_ext}_0_gray.png\"), img_cv2_gray)\n",
    "            cv2.imwrite(os.path.join(DEBUG_OUTPUT_DIR, f\"{image_name_no_ext}_1_mask.png\"), fundus_mask)\n",
    "\n",
    "        # 3. Applica CLAHE, Gaussian Blur, Median Filter all'immagine in scala di grigi\n",
    "        img_clahe = apply_clahe(img_cv2_gray)\n",
    "        img_gaussian_blurred = apply_gaussian_blur(img_clahe)\n",
    "        img_median_filtered = apply_median_filter(img_gaussian_blurred)\n",
    "        fully_processed_gray_data = img_median_filtered\n",
    "\n",
    "        if DEBUG_SAVE_INTERMEDIATE:\n",
    "             cv2.imwrite(os.path.join(DEBUG_OUTPUT_DIR, f\"{image_name_no_ext}_2_fully_processed_gray.png\"), fully_processed_gray_data)\n",
    "\n",
    "        # 4. Applica la maschera per annerire lo sfondo dell'immagine processata\n",
    "        masked_processed_fundus_cv2 = cv2.bitwise_and(fully_processed_gray_data, fully_processed_gray_data, mask=fundus_mask)\n",
    "\n",
    "        if DEBUG_SAVE_INTERMEDIATE:\n",
    "            cv2.imwrite(os.path.join(DEBUG_OUTPUT_DIR, f\"{image_name_no_ext}_3_masked_fundus.png\"), masked_processed_fundus_cv2)\n",
    "\n",
    "        # --- Normalizzazione della Dimensione del Fondo ---\n",
    "        if fundus_bbox:\n",
    "            x, y, w_bbox, h_bbox = fundus_bbox\n",
    "            if w_bbox > 0 and h_bbox > 0:\n",
    "                # Ritaglia il fondo mascherato usando il bounding box\n",
    "                cropped_fundus_cv2 = masked_processed_fundus_cv2[y:y+h_bbox, x:x+w_bbox]\n",
    "\n",
    "                if DEBUG_SAVE_INTERMEDIATE:\n",
    "                    cv2.imwrite(os.path.join(DEBUG_OUTPUT_DIR, f\"{image_name_no_ext}_4_cropped_fundus.png\"), cropped_fundus_cv2)\n",
    "\n",
    "                # Calcola le nuove dimensioni per il fondo ritagliato\n",
    "                target_max_dim_px = int(max(FINAL_IMAGE_SIZE) * FUNDUS_TARGET_SCALE_FACTOR)\n",
    "                \n",
    "                current_max_dim_bbox = max(w_bbox, h_bbox)\n",
    "                scale_ratio = target_max_dim_px / current_max_dim_bbox if current_max_dim_bbox > 0 else 1\n",
    "                \n",
    "                new_w = int(w_bbox * scale_ratio)\n",
    "                new_h = int(h_bbox * scale_ratio)\n",
    "                \n",
    "                # Assicura che le nuove dimensioni siano almeno 1x1\n",
    "                new_w = max(1, new_w)\n",
    "                new_h = max(1, new_h)\n",
    "\n",
    "                interpolation = cv2.INTER_AREA if scale_ratio < 1 else cv2.INTER_CUBIC\n",
    "                resized_cropped_fundus_cv2 = cv2.resize(cropped_fundus_cv2, (new_w, new_h), interpolation=interpolation)\n",
    "                \n",
    "                # Converti il fondo normalizzato e ridimensionato in PIL\n",
    "                image_to_letterbox_pil = cv2_to_pil_grayscale(resized_cropped_fundus_cv2)\n",
    "\n",
    "                if DEBUG_SAVE_INTERMEDIATE:\n",
    "                    image_to_letterbox_pil.save(os.path.join(DEBUG_OUTPUT_DIR, f\"{image_name_no_ext}_5_resized_cropped_fundus.png\"))\n",
    "            else:\n",
    "                # Bounding box non valido (es. w o h = 0)\n",
    "                print(f\"Attenzione: Bounding box del fondo non valido per {image_name}. L'immagine sar nera.\")\n",
    "                image_to_letterbox_pil = Image.new('L', (1,1), 0) # Immagine placeholder piccola da letterboxare\n",
    "                conta_bbox_nulle +=1\n",
    "        else:\n",
    "            # Nessun bounding box trovato (nessun contorno)\n",
    "            print(f\"Attenzione: Nessun bounding box del fondo per {image_name}. L'immagine sar nera.\")\n",
    "            image_to_letterbox_pil = Image.new('L', (1,1), 0) # Immagine placeholder\n",
    "            conta_bbox_nulle +=1\n",
    "            \n",
    "        # 5. Letterbox: inserisce l'immagine (ora il fondo normalizzato) in un canvas 512x512\n",
    "        #    Il colore di padding  0 (nero) perch lo sfondo del fondo  gi nero.\n",
    "        letterboxed_img_pil = letterbox_image(image_to_letterbox_pil, FINAL_IMAGE_SIZE, padding_color=0) \n",
    "        \n",
    "        # 6. Converti di nuovo in NumPy array (CV2) per il salvataggio\n",
    "        final_img_to_save = pil_to_cv2_grayscale(letterboxed_img_pil)\n",
    "        \n",
    "        # 7. Salva l'immagine elaborata\n",
    "        output_filename = os.path.splitext(image_name)[0] + '.png'\n",
    "        output_path = os.path.join(output_class_path, output_filename)\n",
    "        cv2.imwrite(output_path, final_img_to_save)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Errore nel processing di {image_name}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc() # Stampa il traceback completo per un debug pi facile\n",
    "        conta_errate += 1\n",
    "        continue\n",
    "\n",
    "print(f\"Numero di immagini non lette o con errori di processing: {conta_errate}\")\n",
    "print(f\"Numero di immagini con bounding box del fondo nullo o non valido: {conta_bbox_nulle}\")\n",
    "print(\"Processo di suddivisione e preprocessing completato!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c552cfdb-5302-4296-8b8d-51963720d25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## RLDR Check\n",
    "rldr_base_path = \"/home/jupyter-sdm/GENITO/LAVORO_COMPLETO/Dataset_resize/6_RLDR\"\n",
    "total_images_rldr = sum(len(os.listdir(os.path.join(rldr_base_path, str(i)))) for i in range(5))\n",
    "\n",
    "print(f\"Total number of images in the RLDR dataset: {total_images_rldr}\")\n",
    "\n",
    "for cls in range(5):\n",
    "    num_images = len(os.listdir(os.path.join(rldr_base_path, str(cls))))\n",
    "    print(f\"Class {cls}: {num_images} images\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
