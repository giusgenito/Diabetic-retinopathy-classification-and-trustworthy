{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abe00af8-0a0c-411c-8770-2e9fda86d763",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from functools import reduce\n",
    "import warnings\n",
    "def compose(*funcs):\n",
    "    if funcs:\n",
    "        return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)\n",
    "    else:\n",
    "        raise ValueError('Composition of empty sequence not supported.')\n",
    "\n",
    "def letterbox_image(image_pil, target_size_wh, padding_color):\n",
    "    \"\"\"\n",
    "    Resizes an image to a target size while maintaining aspect ratio by adding padding.\n",
    "    The input image (image_pil) is expected to be a PIL Image.\n",
    "    The padding_color is an integer for grayscale images.\n",
    "    \"\"\"\n",
    "    iw, ih = image_pil.size\n",
    "    w_target, h_target = target_size_wh\n",
    "\n",
    "    if iw == 0 or ih == 0: # Handle empty input image\n",
    "        return Image.new('L', target_size_wh, padding_color)\n",
    "\n",
    "    scale = min(w_target/iw, h_target/ih)\n",
    "    nw = int(iw*scale)\n",
    "    nh = int(ih*scale)\n",
    "\n",
    "    # Ensure new dimensions are at least 1 pixel if scaled down significantly\n",
    "    nw = max(1, nw)\n",
    "    nh = max(1, nh)\n",
    "\n",
    "    resized_image = image_pil.resize((nw,nh), Image.BICUBIC)\n",
    "    \n",
    "    new_image = Image.new('L', target_size_wh, padding_color) # 'L' for grayscale\n",
    "    new_image.paste(resized_image, ((w_target-nw)//2, (h_target-nh)//2))\n",
    "    return new_image\n",
    "\n",
    "\n",
    "def convert_to_grayscale(img_bgr):\n",
    "    if len(img_bgr.shape) == 2: return img_bgr\n",
    "    if img_bgr.shape[2] == 1: return img_bgr.reshape(img_bgr.shape[0], img_bgr.shape[1])\n",
    "    # Specific weights for BGR to Grayscale conversion\n",
    "    b, g, r = cv2.split(img_bgr)\n",
    "    gray_img = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "    return gray_img.astype(np.uint8)\n",
    "\n",
    "def apply_clahe(img_gray):\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    return clahe.apply(img_gray)\n",
    "\n",
    "def apply_gaussian_blur(img_gray, kernel_size=(5,5)):\n",
    "    return cv2.GaussianBlur(img_gray, kernel_size, 0)\n",
    "\n",
    "def apply_median_filter(img_gray, kernel_size=5):\n",
    "    return cv2.medianBlur(img_gray, kernel_size)\n",
    "\n",
    "def cv2_to_pil_grayscale(img_cv2):\n",
    "    return Image.fromarray(img_cv2, mode='L')\n",
    "\n",
    "def pil_to_cv2_grayscale(img_pil):\n",
    "    return np.array(img_pil)\n",
    "\n",
    "def segment_fundus_and_create_mask(image_cv2_gray, image_name_for_debug=\"\"):\n",
    "    \"\"\"\n",
    "    Segmenta il fondo oculare e restituisce una maschera binaria e il bounding box del fondo.\n",
    "    Restituisce: (mask, bounding_box) dove bounding_box è (x, y, w, h) o None.\n",
    "    \"\"\"\n",
    "    # Parametri di tuning per la segmentazione\n",
    "    blur_kernel_size_seg = (15, 15) \n",
    "    threshold_value = 30 \n",
    "    morph_kernel_size_open = (15,15) # Kernel per MORPH_OPEN\n",
    "    morph_kernel_size_close = (35,35) # Kernel più grande per MORPH_CLOSE per unire regioni\n",
    "    \n",
    "    blurred_for_seg = cv2.GaussianBlur(image_cv2_gray, blur_kernel_size_seg, 0)\n",
    "    \n",
    "    # Prova cv2.THRESH_OTSU se un valore fisso non è robusto\n",
    "    # _, thresh_img = cv2.threshold(blurred_for_seg, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    _, thresh_img = cv2.threshold(blurred_for_seg, threshold_value, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    kernel_open = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, morph_kernel_size_open)\n",
    "    kernel_close = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, morph_kernel_size_close)\n",
    "    \n",
    "    thresh_img = cv2.morphologyEx(thresh_img, cv2.MORPH_OPEN, kernel_open, iterations=1)\n",
    "    thresh_img = cv2.morphologyEx(thresh_img, cv2.MORPH_CLOSE, kernel_close, iterations=2)\n",
    "\n",
    "    contours, _ = cv2.findContours(thresh_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    mask = np.zeros_like(image_cv2_gray)\n",
    "    bounding_box = None\n",
    "\n",
    "    if contours:\n",
    "        contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "        # Considera di filtrare contorni troppo piccoli rispetto all'area dell'immagine\n",
    "        # min_area_ratio = 0.05 # Esempio: il contorno deve essere almeno il 5% dell'immagine\n",
    "        # if cv2.contourArea(contours[0]) > image_cv2_gray.shape[0] * image_cv2_gray.shape[1] * min_area_ratio:\n",
    "        fundus_contour = contours[0]\n",
    "        hull = cv2.convexHull(fundus_contour)\n",
    "        cv2.drawContours(mask, [hull], -1, (255), thickness=cv2.FILLED)\n",
    "        bounding_box = cv2.boundingRect(hull) # Restituisce (x, y, w, h)\n",
    "        # else:\n",
    "        #    print(f\"Attenzione: Contorno principale troppo piccolo per {image_name_for_debug}. L'immagine risultante potrebbe essere nera.\")\n",
    "    else:\n",
    "        #print(f\"Attenzione: Nessun contorno del fondo trovato per {image_name_for_debug}. L'immagine risultante potrebbe essere nera.\")\n",
    "        pass\n",
    "    return mask, bounding_box\n",
    "\n",
    "# --- Parametri Globali ---\n",
    "FINAL_IMAGE_SIZE = (512, 512)\n",
    "FUNDUS_TARGET_SCALE_FACTOR = 0.9 # Il fondo occuperà il 90% della dimensione maggiore dell'immagine finale\n",
    "DEBUG_SAVE_INTERMEDIATE = False # Imposta a True per salvare immagini di debug\n",
    "DEBUG_OUTPUT_DIR = '/home/jupyter-sdm/GENITO/LAVORO_COMPLETO/Dataset_resize/1_IDRiD_DEBUG/'\n",
    "if DEBUG_SAVE_INTERMEDIATE:\n",
    "    os.makedirs(DEBUG_OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66f71ca7-faef-41d3-be42-1f11439c4996",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  12%|#####7                                          | 812/6835 [06:00<27:38,  3.63it/s]Premature end of JPEG file\n",
      "Processing:  24%|###########                                    | 1610/6835 [12:39<37:34,  2.32it/s]Corrupt JPEG data: 35 extraneous bytes before marker 0xd9\n",
      "Processing:  26%|############1                                  | 1767/6835 [13:59<38:16,  2.21it/s]Corrupt JPEG data: 40 extraneous bytes before marker 0xd9\n",
      "Processing:  26%|############1                                  | 1768/6835 [13:59<32:33,  2.59it/s]Corrupt JPEG data: 37 extraneous bytes before marker 0xd9\n",
      "Processing:  38%|#################7                             | 2576/6835 [20:47<29:22,  2.42it/s]Premature end of JPEG file\n",
      "Processing:  56%|##########################1                    | 3808/6835 [30:00<10:43,  4.71it/s]Corrupt JPEG data: 38 extraneous bytes before marker 0xd9\n",
      "Processing:  56%|##########################1                    | 3809/6835 [30:00<10:49,  4.66it/s]Corrupt JPEG data: 34 extraneous bytes before marker 0xd9\n",
      "Processing:  61%|############################6                  | 4161/6835 [32:40<21:43,  2.05it/s]Premature end of JPEG file\n",
      "Processing:  70%|################################7              | 4767/6835 [36:37<07:19,  4.71it/s]Corrupt JPEG data: 34 extraneous bytes before marker 0xd9\n",
      "Processing:  70%|################################7              | 4768/6835 [36:37<07:14,  4.75it/s]Corrupt JPEG data: 40 extraneous bytes before marker 0xd9\n",
      "Processing:  90%|##########################################2    | 6144/6835 [46:18<02:55,  3.93it/s]Corrupt JPEG data: 40 extraneous bytes before marker 0xd9\n",
      "Processing:  92%|###########################################2   | 6288/6835 [47:19<05:55,  1.54it/s]Premature end of JPEG file\n",
      "Processing:  95%|############################################7  | 6507/6835 [48:44<02:13,  2.47it/s]Corrupt JPEG data: 33 extraneous bytes before marker 0xd9\n",
      "Processing:  95%|############################################7  | 6508/6835 [48:44<01:53,  2.87it/s]Corrupt JPEG data: 35 extraneous bytes before marker 0xd9\n",
      "Processing: 100%|###############################################| 6835/6835 [50:44<00:00,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di immagini non lette o con errori di processing: 0\n",
      "Numero di immagini con bounding box del fondo nullo o non valido: 0\n",
      "Processo di suddivisione e preprocessing completato!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "warnings.filterwarnings(\"ignore\", \"Premature end of JPEG file\")\n",
    "\n",
    "# Percorsi file e cartelle\n",
    "csv_path = '/home/jupyter-sdm/GENITO/DATASETS/DDR/train.csv'  \n",
    "image_dir = '/home/jupyter-sdm/GENITO/DATASETS/DDR/train' \n",
    "final_output_dir = '/home/jupyter-sdm/GENITO/LAVORO_COMPLETO/Dataset_resize/8_DDR'\n",
    "\n",
    "column_class_name = 'grade'\n",
    "colum_image_name = 'image_name'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(csv_path)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Errore: File CSV non trovato a {csv_path}\")\n",
    "    exit()\n",
    "\n",
    "classes = df[column_class_name].unique()\n",
    "for cls in classes:\n",
    "    class_output_path = os.path.join(final_output_dir, str(cls))\n",
    "    os.makedirs(class_output_path, exist_ok=True)\n",
    "\n",
    "conta_errate = 0\n",
    "conta_bbox_nulle = 0\n",
    "\n",
    "for _, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Processing\", ncols=100, ascii=True):\n",
    "    image_name_no_ext = row[colum_image_name]\n",
    "    image_name = image_name_no_ext\n",
    "    image_class = str(row[column_class_name])\n",
    "    src_path = os.path.join(image_dir, image_name_no_ext) # Prova prima .jpg\n",
    "    output_class_path = os.path.join(final_output_dir, image_class)\n",
    "\n",
    "    if not os.path.exists(src_path):\n",
    "        src_path_jpeg = os.path.join(image_dir, image_name_no_ext + \".jpeg\")\n",
    "        if os.path.exists(src_path_jpeg):\n",
    "            src_path = src_path_jpeg\n",
    "            image_name = image_name_no_ext + \".jpeg\" # Aggiorna il nome file per l'output\n",
    "        else:\n",
    "            conta_errate += 1\n",
    "            continue\n",
    "        \n",
    "    img_bgr = cv2.imread(src_path, cv2.IMREAD_COLOR)\n",
    "    \n",
    "    if img_bgr is None:\n",
    "        conta_errate += 1\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # 1. Converti in Scala di Grigi\n",
    "        img_cv2_gray = convert_to_grayscale(img_bgr)\n",
    "\n",
    "        # 2. Segmenta il fondo, crea la maschera e ottieni il bounding box\n",
    "        fundus_mask, fundus_bbox = segment_fundus_and_create_mask(img_cv2_gray.copy(), image_name)\n",
    "\n",
    "        if DEBUG_SAVE_INTERMEDIATE:\n",
    "            cv2.imwrite(os.path.join(DEBUG_OUTPUT_DIR, f\"{image_name_no_ext}_0_gray.png\"), img_cv2_gray)\n",
    "            cv2.imwrite(os.path.join(DEBUG_OUTPUT_DIR, f\"{image_name_no_ext}_1_mask.png\"), fundus_mask)\n",
    "\n",
    "        # 3. Applica CLAHE, Gaussian Blur, Median Filter all'immagine in scala di grigi\n",
    "        img_clahe = apply_clahe(img_cv2_gray)\n",
    "        img_gaussian_blurred = apply_gaussian_blur(img_clahe)\n",
    "        img_median_filtered = apply_median_filter(img_gaussian_blurred)\n",
    "        fully_processed_gray_data = img_median_filtered\n",
    "\n",
    "        if DEBUG_SAVE_INTERMEDIATE:\n",
    "             cv2.imwrite(os.path.join(DEBUG_OUTPUT_DIR, f\"{image_name_no_ext}_2_fully_processed_gray.png\"), fully_processed_gray_data)\n",
    "\n",
    "        # 4. Applica la maschera per annerire lo sfondo dell'immagine processata\n",
    "        masked_processed_fundus_cv2 = cv2.bitwise_and(fully_processed_gray_data, fully_processed_gray_data, mask=fundus_mask)\n",
    "\n",
    "        if DEBUG_SAVE_INTERMEDIATE:\n",
    "            cv2.imwrite(os.path.join(DEBUG_OUTPUT_DIR, f\"{image_name_no_ext}_3_masked_fundus.png\"), masked_processed_fundus_cv2)\n",
    "\n",
    "        # --- Normalizzazione della Dimensione del Fondo ---\n",
    "        if fundus_bbox:\n",
    "            x, y, w_bbox, h_bbox = fundus_bbox\n",
    "            if w_bbox > 0 and h_bbox > 0:\n",
    "                # Ritaglia il fondo mascherato usando il bounding box\n",
    "                cropped_fundus_cv2 = masked_processed_fundus_cv2[y:y+h_bbox, x:x+w_bbox]\n",
    "\n",
    "                if DEBUG_SAVE_INTERMEDIATE:\n",
    "                    cv2.imwrite(os.path.join(DEBUG_OUTPUT_DIR, f\"{image_name_no_ext}_4_cropped_fundus.png\"), cropped_fundus_cv2)\n",
    "\n",
    "                # Calcola le nuove dimensioni per il fondo ritagliato\n",
    "                target_max_dim_px = int(max(FINAL_IMAGE_SIZE) * FUNDUS_TARGET_SCALE_FACTOR)\n",
    "                \n",
    "                current_max_dim_bbox = max(w_bbox, h_bbox)\n",
    "                scale_ratio = target_max_dim_px / current_max_dim_bbox if current_max_dim_bbox > 0 else 1\n",
    "                \n",
    "                new_w = int(w_bbox * scale_ratio)\n",
    "                new_h = int(h_bbox * scale_ratio)\n",
    "                \n",
    "                # Assicura che le nuove dimensioni siano almeno 1x1\n",
    "                new_w = max(1, new_w)\n",
    "                new_h = max(1, new_h)\n",
    "\n",
    "                interpolation = cv2.INTER_AREA if scale_ratio < 1 else cv2.INTER_CUBIC\n",
    "                resized_cropped_fundus_cv2 = cv2.resize(cropped_fundus_cv2, (new_w, new_h), interpolation=interpolation)\n",
    "                \n",
    "                # Converti il fondo normalizzato e ridimensionato in PIL\n",
    "                image_to_letterbox_pil = cv2_to_pil_grayscale(resized_cropped_fundus_cv2)\n",
    "\n",
    "                if DEBUG_SAVE_INTERMEDIATE:\n",
    "                    image_to_letterbox_pil.save(os.path.join(DEBUG_OUTPUT_DIR, f\"{image_name_no_ext}_5_resized_cropped_fundus.png\"))\n",
    "            else:\n",
    "                # Bounding box non valido (es. w o h = 0)\n",
    "                image_to_letterbox_pil = Image.new('L', (1,1), 0) # Immagine placeholder piccola da letterboxare\n",
    "                conta_bbox_nulle +=1\n",
    "        else:\n",
    "            # Nessun bounding box trovato (nessun contorno)\n",
    "            image_to_letterbox_pil = Image.new('L', (1,1), 0) # Immagine placeholder\n",
    "            conta_bbox_nulle +=1\n",
    "            \n",
    "        # 5. Letterbox: inserisce l'immagine (ora il fondo normalizzato) in un canvas 512x512\n",
    "        #    Il colore di padding è 0 (nero) perché lo sfondo del fondo è già nero.\n",
    "        letterboxed_img_pil = letterbox_image(image_to_letterbox_pil, FINAL_IMAGE_SIZE, padding_color=0) \n",
    "        \n",
    "        # 6. Converti di nuovo in NumPy array (CV2) per il salvataggio\n",
    "        final_img_to_save = pil_to_cv2_grayscale(letterboxed_img_pil)\n",
    "        \n",
    "        # 7. Salva l'immagine elaborata\n",
    "        output_filename = os.path.splitext(image_name)[0] + '.png'\n",
    "        output_path = os.path.join(output_class_path, output_filename)\n",
    "        cv2.imwrite(output_path, final_img_to_save)\n",
    "        \n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        conta_errate += 1\n",
    "        continue\n",
    "\n",
    "print(f\"Numero di immagini non lette o con errori di processing: {conta_errate}\")\n",
    "print(f\"Numero di immagini con bounding box del fondo nullo o non valido: {conta_bbox_nulle}\")\n",
    "print(\"Processo di suddivisione e preprocessing completato!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb6caa0-02ba-45d9-9603-01ba759a9878",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
